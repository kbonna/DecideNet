{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assurance (QA)\n",
    "\n",
    "This script identify bad quality data (e.g. with motion artifacts) and returns vectors specifying which subject can be included in second-level analysis. Script features:\n",
    "- identifies high motion subjects\n",
    "- returns DataFrame specifying final sample with high quality data\n",
    "\n",
    "---\n",
    "**Last update**: 19.02.2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bids import BIDSLayout\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = os.path.join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.behavioral_models import load_behavioral_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save exclusion table\n",
    "path_out = os.path.join(path_root, \n",
    "                        'data/main_fmri_study/derivatives/nistats/exclusion')\n",
    "os.makedirs(path_out, exist_ok=True)\n",
    "\n",
    "# Load behavioral data\n",
    "path_beh = os.path.join(path_root, 'data/main_fmri_study/sourcedata/behavioral')\n",
    "beh, meta = load_behavioral_data(path=path_beh)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape\n",
    "n_scans = 730"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load confounds\n",
    "- `conf_files`: list of two lists containing sorted (by subject number) paths to confound files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bids = os.path.join(path_root, 'data/main_fmri_study')\n",
    "\n",
    "layout = BIDSLayout(\n",
    "    root=path_bids,\n",
    "    derivatives=True,\n",
    "    index_metadata=False\n",
    ")\n",
    "\n",
    "conf_filter = {\n",
    "    \"extension\": \"tsv\",\n",
    "    \"desc\": \"confounds\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "conf_files = []\n",
    "\n",
    "for task_dict in [{\"task\": \"prlrew\"}, {\"task\": \"prlpun\"}]:\n",
    "    conf_filter.update(task_dict)\n",
    "    conf_files.append(layout.get(**conf_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusion criteria\n",
    "\n",
    "Two types of exclusion criteria are applies. Fist, exclusion based on excessive head motion is performed. We consider three criteria for volume-to-volume movements (**framewise displacement; FD**):\n",
    "- mean FD should not exceed 0.2mm (`thr_fd_mean`)\n",
    "- max FD should not exceed 5mm (`thr_fd_max`)\n",
    "- number of volumes with FD > 0.5mm should not exceed 20% of total volumes (`thr_fd_gt05`)\n",
    "\n",
    "Second, we excluded additional subjects based on other factors e.g. errors in acquisition, chance-level performance. We excluded:\n",
    "- subject `m19` (both conditions): due to flipped response grips\n",
    "- subject `m32` (pun condition): due to failed realignment (TODO: fix preprocessing for that subject)\n",
    "\n",
    "Columns in `exclusions.csv` are coded accordingly:\n",
    "- `ok_fd_<condition>`: False for subjects with excessive movement during \\<condition\\>, True otherwise\n",
    "- `ok_err_<condition>`: False for additional subjects excluded from specific condition, True otherwise\n",
    "- `ok_<condition>`: includes both movement and additional exclusion criteria for specific condition, False for subjects excluded from analysis, True for subjects included in analysis \n",
    "- `ok_all`: includes all exclusion criteria from both conditions, represent final inclusion / exclusion vector for second level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusion threshold\n",
    "thr_fd_mean = 0.2\n",
    "thr_fd_max = 5\n",
    "thr_fd_gt05 = 0.2 * n_scans\n",
    "\n",
    "# Additional exclusions\n",
    "error_rew = ['m19']\n",
    "error_pun = ['m19', 'm32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_stats = np.zeros((n_subjects, n_conditions, 3))\n",
    "\n",
    "for sub in range(n_subjects):\n",
    "    for con in range(n_conditions):\n",
    "\n",
    "        df = pd.read_csv(conf_files[con][sub], sep='\\t')\n",
    "\n",
    "        fd_mean = df['framewise_displacement'].mean()\n",
    "        fd_max = df['framewise_displacement'].max()\n",
    "        fd_gt05 = (df['framewise_displacement'] > 0.5).sum()\n",
    "        \n",
    "        fd_stats[sub, con, :] = [fd_mean, fd_max, fd_gt05]\n",
    "\n",
    "# Create exclusion DataFrame\n",
    "df = pd.DataFrame(data=np.hstack((fd_stats[:,0,:], fd_stats[:,1,:])),\n",
    "                  columns=['fd_mean_rew', 'fd_max_rew', 'fd_gt05_rew',\n",
    "                           'fd_mean_pun', 'fd_max_pun', 'fd_gt05_pun'])\n",
    "df.insert(0, 'sub', meta['dim1'])\n",
    "\n",
    "# Apply exclusion criteria for motion\n",
    "df['ok_fd_rew'] = (df['fd_mean_rew'] < thr_fd_mean) \\\n",
    "                   & (df['fd_max_rew'] < thr_fd_max) \\\n",
    "                   & (df['fd_gt05_rew'] < thr_fd_gt05)\n",
    "df['ok_fd_pun'] = (df['fd_mean_pun'] < thr_fd_mean) \\\n",
    "                   & (df['fd_max_pun'] < thr_fd_max) \\\n",
    "                   & (df['fd_gt05_pun'] < thr_fd_gt05)\n",
    "\n",
    "# Apply additional exclusion criteria (e.g. acquisition errors)\n",
    "df['ok_err_rew'] = pd.Series((True, ) * n_subjects)\n",
    "for sub in error_rew:\n",
    "    df.loc[np.flatnonzero(df['sub'] == sub), 'ok_err_rew'] = False    \n",
    "df['ok_err_pun'] = pd.Series((True, ) * n_subjects)\n",
    "for sub in error_pun:\n",
    "    df.loc[np.flatnonzero(df['sub'] == sub), 'ok_err_pun'] = False  \n",
    "\n",
    "# Create summary for conditions & entire task\n",
    "df['ok_rew'] = df['ok_fd_rew'] & df['ok_err_rew']\n",
    "df['ok_pun'] = df['ok_fd_pun'] & df['ok_err_pun']\n",
    "df['ok_all'] = df['ok_rew'] & df['ok_pun']\n",
    "\n",
    "df.to_csv(os.path.join(path_out, 'exclusion.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
