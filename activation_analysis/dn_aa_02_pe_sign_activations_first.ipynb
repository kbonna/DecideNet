{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('/home/kmb/Desktop/Neuroscience/Projects/BONNA_decide_net/code')\n",
    "import nibabel as nib\n",
    "from dn_utils.behavioral_models import load_behavioral_data                          \n",
    "from bids import BIDSLayout\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, show\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.reporting import plot_design_matrix\n",
    "from nistats.thresholding import map_threshold\n",
    "from nistats.design_matrix import make_first_level_design_matrix\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load task onsets\n",
    "\n",
    "Load behavioral data containg relevant task onsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_dir = \"/home/kmb/Desktop/Neuroscience/Projects/BONNA_decide_net/\" \\\n",
    "          \"data/main_fmri_study/sourcedata/behavioral\"\n",
    "beh, meta = load_behavioral_data(root=beh_dir)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query neuroimaging dataset (path extraction)\n",
    "\n",
    "Using BIDSLayout object query BIDS dataset to pull out necessary files.\n",
    "- `anat_files`: sorted list of preprocessed T1w images\n",
    "- `fmri_files`: list of two lists containing sorted (by subject number) paths to imaging files, first list corresponds to reward condition of PRL task and second list corresponds to punishment condition of PRL task\n",
    "- `conf_files`: list of two lists containing sorted (by subject number) paths to confound files\n",
    "- `mask_files`: brain mask files for fmri sequencnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = \"/home/kmb/Desktop/Neuroscience/Projects/BONNA_decide_net/data/main_fmri_study\"\n",
    "\n",
    "layout = BIDSLayout(\n",
    "    root=bids_dir,\n",
    "    derivatives=True,\n",
    "    validate=True,\n",
    "    index_metadata=False\n",
    ")\n",
    "\n",
    "anat_filter = {\n",
    "    \"extension\": [\".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"suffix\": \"T1w\",\n",
    "    \"desc\": \"preproc\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "fmri_filter = {\n",
    "    \"extension\": [\".nii\", \".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"suffix\": \"bold\",\n",
    "    \"desc\": \"preproc\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "conf_filter = {\n",
    "    \"extension\": \"tsv\",\n",
    "    \"desc\": \"confounds\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "mask_filter = {\n",
    "    \"extension\": [\".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"desc\": \"brain\",\n",
    "    \"suffix\": \"mask\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "anat_files = layout.get(**anat_filter)\n",
    "\n",
    "fmri_files, conf_files, mask_files = [], [], []\n",
    "\n",
    "for task_dict in [{\"task\": \"prlrew\"}, {\"task\": \"prlpun\"}]:\n",
    "    fmri_filter.update(task_dict)\n",
    "    conf_filter.update(task_dict)\n",
    "    mask_filter.update(task_dict)\n",
    "    fmri_files.append(layout.get(**fmri_filter))\n",
    "    conf_files.append(layout.get(**conf_filter))\n",
    "    mask_files.append(layout.get(**mask_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single subject analysis\n",
    "\n",
    "Here, first level GLM analysis is performed for each subject. For each imaging sequence following steps are applied:\n",
    "1. relevant files are loaded: anatomical, functional, brain mask for functional file\n",
    "2. `confounds` dataframe is loaded and filtered. Included confounds are: six motion parameters and first five a_comp_cor regressors\n",
    "4. glm model is evaluated (beta estimates for all regressors)\n",
    "5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1\n",
    "Regressors of interest:\n",
    "- +PE regressor (1 for correct answer and 0 for incorrect)\n",
    "- -PE regressor (1 for incorrect answer and 0 for correct)\n",
    "\n",
    "Regressors of no interest:\n",
    "- missPE regressor (1 for trials where there was no answer)\n",
    "- confounds\n",
    "\n",
    "Contrast:\n",
    "- +PE minus -PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/home/kmb/Desktop/Neuroscience/Projects/BONNA_decide_net/data/\"\\\n",
    "          \"main_fmri_study/derivatives/nistats/pesign_separate\"\n",
    "\n",
    "# Specify GLM\n",
    "fmri_glm = FirstLevelModel(\n",
    "    t_r=2,\n",
    "    noise_model='ar1',\n",
    "    drift_model='cosine',\n",
    "    period_cut=128,\n",
    "    standardize=False,\n",
    "    hrf_model='spm',\n",
    "    smoothing_fwhm=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate regressors for +PE and -PE\n",
    "for sub_idx in range(n_subjects):\n",
    "\n",
    "    print(f\"Analyzing sub-{meta['dim1'][sub_idx]}...\")\n",
    "    \n",
    "    for con_idx in range(n_conditions):\n",
    "\n",
    "        # Load imaging data\n",
    "        anat_img = nib.load(anat_files[sub_idx])\n",
    "        fmri_img = nib.load(fmri_files[con_idx][sub_idx])\n",
    "        fmri_glm.mask = nib.load(mask_files[con_idx][sub_idx])\n",
    "\n",
    "        # Create single subject regressors\n",
    "        out_onset = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_out')]\n",
    "        out_duration = np.zeros(n_trials)\n",
    "\n",
    "        resp_type = beh[sub_idx, con_idx, :, meta['dim4'].index('response')]\n",
    "        won_bool = beh[sub_idx, con_idx, :, meta['dim4'].index('won_bool')]\n",
    "        pe_type = (resp_type != 0) * ((won_bool - .5) * 2)\n",
    "\n",
    "        events_array = np.hstack((out_onset[:, np.newaxis],\n",
    "                                  out_duration[:, np.newaxis],\n",
    "                                  pe_type[:, np.newaxis]))\n",
    "\n",
    "        events = pd.DataFrame(events_array, columns=['onset', 'duration', 'trial_type'])\n",
    "        events.loc[events.trial_type ==  1, \"trial_type\"] = 'pe_sgn_pos'\n",
    "        events.loc[events.trial_type == -1, \"trial_type\"] = 'pe_sgn_neg'\n",
    "        events.loc[events.trial_type ==  0, \"trial_type\"] = 'pe_miss'\n",
    "\n",
    "        # Grab and filter confounds\n",
    "        confounds_relevant = ['a_comp_cor_00', 'a_comp_cor_01', 'a_comp_cor_02', \n",
    "                              'a_comp_cor_03', 'a_comp_cor_04', 'a_comp_cor_05', \n",
    "                              'trans_x', 'trans_y', 'trans_z', \n",
    "                              'rot_x', 'rot_y', 'rot_z']\n",
    "\n",
    "        confounds = pd.read_csv(conf_files[con_idx][sub_idx], sep='\\t')\n",
    "        confounds = confounds[confounds_relevant]\n",
    "\n",
    "        # Fit GLM\n",
    "        fmri_glm = fmri_glm.fit(\n",
    "            fmri_img,\n",
    "            events=events,\n",
    "            confounds=confounds);\n",
    "\n",
    "        # Define contrast\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "        conditions = {\n",
    "            'pe_sgn_pos': np.zeros(design_matrix.shape[1]),\n",
    "            'pe_sgn_neg': np.zeros(design_matrix.shape[1]),\n",
    "        }\n",
    "        conditions['pe_sgn_pos'][list(design_matrix.columns).index('pe_sgn_pos')] = 1\n",
    "        conditions['pe_sgn_neg'][list(design_matrix.columns).index('pe_sgn_neg')] = 1\n",
    "        pos_minus_neg = conditions['pe_sgn_pos'] - conditions['pe_sgn_neg']\n",
    "\n",
    "        # Compute statistical map and save it\n",
    "        z_map = fmri_glm.compute_contrast(\n",
    "            pos_minus_neg,\n",
    "            stat_type='t')\n",
    "\n",
    "        z_map_fname = f\"sub-{meta['dim1'][sub_idx]}_task-prl{meta['dim2'][con_idx]}_desc-pesign_tmap\"\n",
    "        nib.save(z_map, os.path.join(out_dir, z_map_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2\n",
    "Regressors of interest:\n",
    "- parametrically modulated PE sign regressor (1 for correct answer and -1 for incorrect)\n",
    "\n",
    "Regressors of no interest:\n",
    "- missPE regressor (1 for trials where there was no answer)\n",
    "- confounds\n",
    "\n",
    "Contrast:\n",
    "- main effect of modulated PE sign regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/home/kmb/Desktop/Neuroscience/Projects/BONNA_decide_net/data/\"\\\n",
    "          \"main_fmri_study/derivatives/nistats/pesign_modulated\"\n",
    "\n",
    "# Specify GLM\n",
    "fmri_glm = FirstLevelModel(\n",
    "    t_r=2,\n",
    "    noise_model='ar1',\n",
    "    drift_model='cosine',\n",
    "    period_cut=128,\n",
    "    standardize=False,\n",
    "    hrf_model='spm',\n",
    "    smoothing_fwhm=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single modulated PE regressor\n",
    "for sub_idx in range(n_subjects):\n",
    "\n",
    "    print(f\"Analyzing sub-{meta['dim1'][sub_idx]}...\")\n",
    "    \n",
    "    for con_idx in range(n_conditions):\n",
    "\n",
    "        # Load imaging data\n",
    "        anat_img = nib.load(anat_files[sub_idx])\n",
    "        fmri_img = nib.load(fmri_files[con_idx][sub_idx])\n",
    "        fmri_glm.mask = nib.load(mask_files[con_idx][sub_idx])\n",
    "\n",
    "        # This is done throught manual creation of design matrix using \n",
    "        # make_design_matrix function from nistats. Additional data is needed, since \n",
    "        # number of scans cannot be inferred automatically.\n",
    "        n_scans = 730\n",
    "        t_r = 2\n",
    "        frame_times = np.arange(n_scans) * t_r\n",
    "\n",
    "        # Get subject data\n",
    "        out_onset = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_out')]\n",
    "        out_duration = np.zeros(n_trials)\n",
    "        resp_type = beh[sub_idx, con_idx, :, meta['dim4'].index('response')]\n",
    "        won_bool = beh[sub_idx, con_idx, :, meta['dim4'].index('won_bool')]\n",
    "\n",
    "        # Create parametrically modulated regressor\n",
    "        # Grab only outcome events for trials without missing response \n",
    "        events_mod_array = np.hstack((out_onset[resp_type != 0][:, np.newaxis],\n",
    "                                      out_duration[resp_type != 0][:, np.newaxis],\n",
    "                                      np.ones(np.sum(resp_type != 0))[:, np.newaxis],\n",
    "                                      (won_bool[resp_type != 0][:, np.newaxis] - .5) * 2))\n",
    "        events_mod = pd.DataFrame(events_mod_array,\n",
    "                                  columns=['onset', 'duration', 'trial_type', 'modulation'])\n",
    "        events_mod.loc[events_mod.trial_type ==  1, \"trial_type\"] = 'pe_sgn_mod'\n",
    "        events_mod['modulation'] -= events_mod['modulation'].mean()\n",
    "\n",
    "        dm_mod = make_first_level_design_matrix(\n",
    "            frame_times,\n",
    "            events_mod,\n",
    "            drift_model=None\n",
    "        )\n",
    "\n",
    "        # Grab and filter confounds\n",
    "        confounds_relevant = ['a_comp_cor_00', 'a_comp_cor_01', 'a_comp_cor_02', \n",
    "                              'a_comp_cor_03', 'a_comp_cor_04', 'a_comp_cor_05', \n",
    "                              'trans_x', 'trans_y', 'trans_z', \n",
    "                              'rot_x', 'rot_y', 'rot_z']\n",
    "\n",
    "        confounds = pd.read_csv(conf_files[con_idx][sub_idx], sep='\\t')\n",
    "        confounds = confounds[confounds_relevant]\n",
    "\n",
    "        # Create design matrix without parametrically modulated regressors\n",
    "        events_array = np.hstack((out_onset[resp_type == 0][:, np.newaxis],\n",
    "                                  out_duration[resp_type == 0][:, np.newaxis],\n",
    "                                  np.ones(np.sum(resp_type == 0))[:, np.newaxis]))\n",
    "        events = pd.DataFrame(events_array, columns=['onset', 'duration', 'trial_type'])\n",
    "        events.loc[events.trial_type ==  1, \"trial_type\"] = 'pe_miss'\n",
    "\n",
    "        # Concatenate modulated regressors and confounds\n",
    "        add_regs = np.hstack((dm_mod['pe_sgn_mod'][:, np.newaxis], np.array(confounds)))\n",
    "        add_reg_names = ['pe_sgn_mod'] + list(confounds.columns)\n",
    "\n",
    "        # Create final design matrix\n",
    "        dm_final = make_first_level_design_matrix(\n",
    "            frame_times,\n",
    "            events,\n",
    "            add_regs=add_regs,\n",
    "            add_reg_names=add_reg_names\n",
    "        )\n",
    "\n",
    "        # Fit GLM\n",
    "        fmri_glm = fmri_glm.fit(\n",
    "            fmri_img,\n",
    "            design_matrices=dm_final\n",
    "        )\n",
    "\n",
    "        # Define contrast\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "        conditions = {\n",
    "            'pe_sgn_mod': np.zeros(design_matrix.shape[1]),\n",
    "        }\n",
    "        conditions['pe_sgn_mod'][list(design_matrix.columns).index('pe_sgn_mod')] = 1\n",
    "\n",
    "        # Compute statistical map and save it\n",
    "        z_map = fmri_glm.compute_contrast(\n",
    "            conditions['pe_sgn_mod'],\n",
    "            stat_type='t')\n",
    "\n",
    "        z_map_fname = f\"sub-{meta['dim1'][sub_idx]}_task-prl{meta['dim2'][con_idx]}_desc-pesign_tmap\"\n",
    "        nib.save(z_map, os.path.join(out_dir, z_map_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show example statistical map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) Display first-level results in the brain space\n",
    "_, threshold = map_threshold(\n",
    "    z_map, \n",
    "    level=.05, \n",
    "    height_control='fpr')\n",
    "\n",
    "plot_stat_map(\n",
    "    z_map, \n",
    "    bg_img=anat_img,\n",
    "    threshold=3,\n",
    "    display_mode='z')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
