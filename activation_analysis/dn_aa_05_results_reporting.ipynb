{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from nilearn import plotting, image\n",
    "from nistats.thresholding import map_threshold\n",
    "from nistats.reporting import get_clusters_table\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = os.path.join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.glm_utils import (add_clusters_labels, load_first_level_stat_maps,\n",
    "    extract_img_value_for_mni_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_nistats = os.path.join(path_root, 'data/main_fmri_study/derivatives/nistats')\n",
    "path_exclusion_csv = os.path.join(path_nistats, 'exclusion/exclusion.csv')\n",
    "path_first_level_output = os.path.join(path_nistats, 'first_level_output')\n",
    "path_second_level_output = os.path.join(path_nistats, 'second_level_output')\n",
    "path_templates = os.path.join(path_nistats, 'templates')\n",
    "path_atlases_summary = os.path.join(path_templates, 'atlases_summary.json')\n",
    "\n",
    "# Directory to save resulting figures\n",
    "path_out = os.path.join(path_nistats, 'results')\n",
    "os.makedirs(path_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load brain template\n",
    "\n",
    "Here, anatomical brain template is loaded to serve as a background for activation maps. We use the same template that is used in fmriprep for coregistration, i.e. MNI 2009c asymmetric template. Two image files are loaded and one is created:\n",
    "- `img_mni_09c_t1`: T1 version of template without brain extraction\n",
    "- `img_mni_09c_mask`: brain mask for T1 template image\n",
    "- `img_mni_09c_clipped`: masked T1 template (brain extracted from T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNI 2009c template\n",
    "path_mni = os.path.join(\n",
    "    path_templates, \n",
    "    'mni_icbm152_nlin_asym_09c_nifti/mni_icbm152_nlin_asym_09c')\n",
    "img_mni_09c_t1 = nib.load(\n",
    "    os.path.join(path_mni, 'mni_icbm152_t1_tal_nlin_asym_09c.nii'))\n",
    "img_mni_09c_mask = nib.load(\n",
    "    os.path.join(path_mni, 'mni_icbm152_t1_tal_nlin_asym_09c_mask.nii'))\n",
    "img_mni_09c_clipped = nib.Nifti1Image(\n",
    "    img_mni_09c_t1.get_fdata() * img_mni_09c_mask.get_fdata(), \n",
    "    img_mni_09c_t1.affine, \n",
    "    img_mni_09c_t1.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second level SPMs\n",
    "spm_perr_inc = nib.load(os.path.join(\n",
    "    path_second_level_output, \n",
    "    'statmap-2nd_effect-perr_combined_pos.nii'))\n",
    "spm_perr_dec = nib.load(os.path.join(\n",
    "    path_second_level_output, \n",
    "    'statmap-2nd_effect-perr_combined_neg.nii'))\n",
    "spm_perr_rew_minus_pun = nib.load(os.path.join(\n",
    "    path_second_level_output, \n",
    "    'statmap-2nd_effect-perr_rew_minus_pun.nii'))\n",
    "spm_perr_pun_minus_rew = nib.load(os.path.join(\n",
    "    path_second_level_output, \n",
    "    'statmap-2nd_effect-perr_pun_minus_rew.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load brain atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intigerize_keys = lambda dict_: {int(k): v for k, v in dict_.items()}\n",
    "\n",
    "# Load atlases summary\n",
    "atlases_summary = json.loads(open(path_atlases_summary, 'r').read())\n",
    "\n",
    "# Extract relevant information\n",
    "names_atlases = atlases_summary.keys()\n",
    "img_atlases = [nib.load(atlas_dict['path_nifti']) \n",
    "               for atlas_dict in atlases_summary.values()]\n",
    "label_codes_atlases = [intigerize_keys(atlas_dict['label_codes']) \n",
    "                       for atlas_dict in atlases_summary.values()]\n",
    "\n",
    "def extend_clusters_table(clusters_table):\n",
    "    '''Add rogion label columns according to different brain atlases.'''\n",
    "    for name, img, label_codes in zip(names_atlases, \n",
    "                                      img_atlases, \n",
    "                                      label_codes_atlases):\n",
    "        add_clusters_labels(clusters_table, img, label_codes, name, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined effect of prediction error encoding\n",
    "\n",
    "Here we threshold second level statistical paramet maps (spm's) for prediction error effect combined for both task conditions. We use two-sided test with false discovery rate (FDR) correction to detect brain regions:\n",
    "- with activity scaling positively with increasing prediction error (+PE regions)\n",
    "- with activity scaling negatively with increasing prediction error (-PE regions)\n",
    "\n",
    "We used corrected p-value threshold of 0.00001 and cluster forming threshold of 20 connected voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_perr_inc, thr_perr_inc = map_threshold(\n",
    "    spm_perr_inc,\n",
    "    mask_img=img_mni_09c_mask,\n",
    "    alpha=0.0001,\n",
    "    height_control='fdr',\n",
    "    cluster_threshold=20,\n",
    "    two_sided=True\n",
    ")\n",
    "\n",
    "plotting.plot_img(\n",
    "    activations_perr_inc, \n",
    "    bg_img=img_mni_09c_clipped,\n",
    "    display_mode='z',\n",
    "    cut_coords=(-12, 2, 27, 45, 70),\n",
    "    threshold=thr_perr_inc,\n",
    "    vmax=9,\n",
    "    vmin=-9,\n",
    "    black_bg=False,\n",
    "    colorbar=True,\n",
    "    cmap='cold_hot'\n",
    ")\n",
    "\n",
    "clusters_perr_inc = get_clusters_table(\n",
    "    spm_perr_inc, \n",
    "    stat_threshold=thr_perr_inc, \n",
    "    cluster_threshold=20)\n",
    "clusters_perr_dec = get_clusters_table(\n",
    "    spm_perr_dec, \n",
    "    stat_threshold=thr_perr_inc, \n",
    "    cluster_threshold=20)\n",
    "\n",
    "extend_clusters_table(clusters_perr_inc)\n",
    "extend_clusters_table(clusters_perr_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference in prediction error coding between reward and punishment conditions\n",
    "\n",
    "Here we threshold second level statistical paramet maps (spm's) for prediction error effect difference between reward and punishment conditions. We use two-sided test with false discovery rate (FDR) correction to detect brain regions:\n",
    "- for which slope of relationship between activity and PE is larger in reward than in punishemnt condition\n",
    "- for which slope of relationship between activity and PE is smaller in reward than in punishemnt condition\n",
    "\n",
    "We used corrected p-value threshold of 0.0001 and cluster forming threshold of 20 connected voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_perr_rew_minus_pun, thr_perr_rew_minus_pun = map_threshold(\n",
    "    spm_perr_rew_minus_pun,\n",
    "    mask_img=img_mni_09c_mask,\n",
    "    alpha=0.0001,\n",
    "    height_control='fdr',\n",
    "    cluster_threshold=20,\n",
    "    two_sided=True\n",
    ")\n",
    "\n",
    "plotting.plot_img(\n",
    "    activations_perr_rew_minus_pun, \n",
    "    bg_img=img_mni_09c_clipped,\n",
    "    display_mode='z',\n",
    "    cut_coords=(16, 30, 41),\n",
    "    threshold=thr_perr_rew_minus_pun,\n",
    "    black_bg=False,\n",
    "    colorbar=True,\n",
    "    vmin=0,\n",
    "    vmax=9,\n",
    "    cmap='hot'\n",
    ")\n",
    "\n",
    "clusters_perr_rew_minus_pun = get_clusters_table(\n",
    "    spm_perr_rew_minus_pun, \n",
    "    stat_threshold=thr_perr_rew_minus_pun, \n",
    "    cluster_threshold=20)\n",
    "\n",
    "extend_clusters_table(clusters_perr_rew_minus_pun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-hoc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load exclusion table\n",
    "df_exclusion = pd.read_csv(path_exclusion_csv, index_col=0)\n",
    "ok_index = df_exclusion.index[df_exclusion['ok_all']]\n",
    "\n",
    "# Load first level stat maps\n",
    "stat_maps = load_first_level_stat_maps(\n",
    "    os.path.join(path_first_level_output, 'out_perr'), \n",
    "    ['prlrew', 'prlpun'])\n",
    "stat_maps_ok = {con: [stat_maps[con][i] for i in ok_index] for con in stat_maps}\n",
    "\n",
    "# Extract individual beta values for clusters\n",
    "peak_individual_betas = {}\n",
    "for row, cluster in clusters_perr_rew_minus_pun.iterrows():\n",
    "    \n",
    "    peak_mni_coords = np.array(cluster.loc[['X', 'Y', 'Z']], dtype='float')\n",
    "    betas_prlrew = [extract_img_value_for_mni_coords(peak_mni_coords, img) \n",
    "                    for img in stat_maps_ok['prlrew']]\n",
    "    betas_prlpun = [extract_img_value_for_mni_coords(peak_mni_coords, img) \n",
    "                    for img in stat_maps_ok['prlpun']]\n",
    "    \n",
    "    peak_individual_betas[tuple(peak_mni_coords)] = pd.DataFrame(\n",
    "        data={'prlrew': betas_prlrew, 'prlpun': betas_prlpun})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for peak_mni_coords, df in peak_individual_betas.items():\n",
    "\n",
    "    tstat = ss.ttest_ind(df['prlrew'], df['prlpun']).statistic\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4), facecolor='w')\n",
    "\n",
    "    bar_xticks = (0.1, 0.9) \n",
    "    bar_xlim = (-0.5, 1.5)\n",
    "    bar_width = 0.2\n",
    "\n",
    "    ax.bar(\n",
    "        x=bar_xticks, \n",
    "        height=df.mean(),\n",
    "        width=bar_width,\n",
    "        color=['#93c47d', '#e06666'],\n",
    "        yerr=df.std(),\n",
    "        linewidth=1,\n",
    "        edgecolor='k'\n",
    "    )\n",
    "    ax.axhline(0, color='k', lineWidth=1)\n",
    "\n",
    "    ax.set_xlim(*bar_xlim)\n",
    "    ax.set_xticks(bar_xticks)\n",
    "    ax.set_xticklabels(['reward', 'punishment'])\n",
    "    ax.set_ylabel('a.u.')\n",
    "    ax.set_title(f'peak: {peak_mni_coords} → t-stat: {tstat:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export clusters table\n",
    "# clusters_perr_inc.to_csv(os.path.join(\n",
    "#     path_out, 'clusters_perr_inc.csv'))\n",
    "# clusters_perr_dec.to_csv(os.path.join(\n",
    "#     path_out, 'clusters_perr_dec.csv'))\n",
    "# clusters_perr_rew_minus_pun.to_csv(os.path.join(\n",
    "#     path_out, 'clusters_perr_rew_minus_pun.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 64-bit ('decidenet': conda)",
   "language": "python",
   "name": "decidenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
