{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_later():\n",
    "    # (optional) Display first-level results in the brain space\n",
    "    _, threshold = map_threshold(\n",
    "        z_map, \n",
    "        level=.05, \n",
    "        height_control='fpr')\n",
    "\n",
    "    plot_stat_map(\n",
    "        z_map, \n",
    "        bg_img=anat_img,\n",
    "        threshold=3,\n",
    "        display_mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First level GLM analysis\n",
    "\n",
    "This script performs subject level modeling of BOLD response. For each subject and condition, single GLM matrix is created and associated beta values are estimated. Script features: \n",
    "- loads preprocessed fMRI data\n",
    "\n",
    "---\n",
    "**Last update**: 07.02.2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmb/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from bids import BIDSLayout\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, show\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.reporting import plot_design_matrix\n",
    "from nistats.thresholding import map_threshold\n",
    "from nistats.design_matrix import make_first_level_design_matrix\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = os.path.join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.behavioral_models import load_behavioral_data                    \n",
    "from dn_utils.glm_utils import Regressor, my_make_first_level_design_matrix\n",
    "from dn_utils.misc import mkdir_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of beh array: (32, 2, 110, 23)\n",
      "Conditions [(0, 'rew'), (1, 'pun')]\n",
      "Columns: [(0, 'block'), (1, 'block_bci'), (2, 'side'), (3, 'side_bci'), (4, 'magn_left'), (5, 'magn_right'), (6, 'response'), (7, 'rt'), (8, 'won_bool'), (9, 'won_magn'), (10, 'acc_after_trial'), (11, 'onset_iti'), (12, 'onset_iti_plan'), (13, 'onset_iti_glob'), (14, 'onset_dec'), (15, 'onset_dec_plan'), (16, 'onset_dec_glob'), (17, 'onset_isi'), (18, 'onset_isi_plan'), (19, 'onset_isi_glob'), (20, 'onset_out'), (21, 'onset_out_plan'), (22, 'onset_out_glob')]\n"
     ]
    }
   ],
   "source": [
    "# Load behavioral data\n",
    "path_beh = os.path.join(path_root, 'data/main_fmri_study/sourcedata/behavioral')\n",
    "beh, meta = load_behavioral_data(path=path_beh)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query neuroimaging dataset\n",
    "\n",
    "Using BIDSLayout object query BIDS dataset to pull out necessary files.\n",
    "- `anat_files`: sorted list of preprocessed T1w images\n",
    "- `fmri_files`: list of two lists containing sorted (by subject number) paths to imaging files, first list corresponds to reward condition of PRL task and second list corresponds to punishment condition of PRL task\n",
    "- `conf_files`: list of two lists containing sorted (by subject number) paths to confound files\n",
    "- `mask_files`: brain mask files for fmri sequencnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bids = os.path.join(path_root, 'data/main_fmri_study')\n",
    "\n",
    "layout = BIDSLayout(\n",
    "    root=path_bids,\n",
    "    derivatives=True,\n",
    "    validate=True,\n",
    "    index_metadata=False\n",
    ")\n",
    "\n",
    "anat_filter = {\n",
    "    \"extension\": [\".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"suffix\": \"T1w\",\n",
    "    \"desc\": \"preproc\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "fmri_filter = {\n",
    "    \"extension\": [\".nii\", \".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"suffix\": \"bold\",\n",
    "    \"desc\": \"preproc\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "conf_filter = {\n",
    "    \"extension\": \"tsv\",\n",
    "    \"desc\": \"confounds\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "mask_filter = {\n",
    "    \"extension\": [\".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"desc\": \"brain\",\n",
    "    \"suffix\": \"mask\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "anat_files = layout.get(**anat_filter)\n",
    "\n",
    "fmri_files, conf_files, mask_files = [], [], []\n",
    "\n",
    "for task_dict in [{\"task\": \"prlrew\"}, {\"task\": \"prlpun\"}]:\n",
    "    fmri_filter.update(task_dict)\n",
    "    conf_filter.update(task_dict)\n",
    "    mask_filter.update(task_dict)\n",
    "    fmri_files.append(layout.get(**fmri_filter))\n",
    "    conf_files.append(layout.get(**conf_filter))\n",
    "    mask_files.append(layout.get(**mask_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load task modulations\n",
    "Here, modulations for model-based fMRI are downloaded. Two modulations apply to decision phase (expected probability of choosing correct box `wcor` and Pascalian expected value `exvl`) and one modulation apply to outcome phase (probabilistic prediction error `perr`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_modulations = os.path.join(path_root, \n",
    "                                'data/main_fmri_study/derivatives/nistats/modulations')\n",
    "\n",
    "# Load parametric modulations\n",
    "modulations_wcor = np.load(os.path.join(path_modulations,'modulations_wcor.npy'))\n",
    "modulations_exvl = np.load(os.path.join(path_modulations,'modulations_exvl.npy'))\n",
    "modulations_perr = np.load(os.path.join(path_modulations,'modulations_perr.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single subject analysis\n",
    "\n",
    "Here, first level GLM analysis is performed for each subject and task condition. `FirstLevelModel` instance is created initialized with proper GLM settings (hemodynamic response function, drift and noise model, high pass filter, smoothing kernel). Then, for each imaging sequence following steps are applied:\n",
    "1. Data files are loaded (T1w anatomical image, EPI sequence, brain mask for EPI sequence, confounds table.\n",
    "2. Task events onsets are loaded.\n",
    "    - `onset_dec`: onset time of decision phase\n",
    "    - `onset_res`: onset time of subject response\n",
    "    - `onset_out`: onset time of outcome phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for storing output nistats derivatives\n",
    "path_out = os.path.join(path_root, 'data/main_fmri_study/derivatives/nistats/first_level')\n",
    "mkdir_safe(path_out)\n",
    "\n",
    "# Specify GLM\n",
    "fmri_glm = FirstLevelModel(\n",
    "    t_r=2,\n",
    "    hrf_model='spm',\n",
    "    drift_model='cosine',\n",
    "    noise_model='ar1',\n",
    "    high_pass=0.0078125, \n",
    "    standardize=True,\n",
    "    smoothing_fwhm=6)\n",
    "\n",
    "# Name of relevant confounds\n",
    "confounds_relevant = [col for col in pd.read_csv(conf_files[0][0], sep='\\t').columns \n",
    "                      if 'rot' in col or 'trans' in col]\n",
    "\n",
    "# Times of image acquisition in seconds\n",
    "n_scans, t_r = 730, 2\n",
    "frame_times = np.arange(n_scans) * t_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sub_idx in range(n_subjects):\n",
    "#     for con_idx in range(n_conditions):\n",
    "sub_idx = 0\n",
    "con_idx = 0\n",
    "\n",
    "# Load subject data\n",
    "anat_img = nib.load(anat_files[sub_idx])\n",
    "fmri_img = nib.load(fmri_files[con_idx][sub_idx])\n",
    "fmri_glm.mask = nib.load(mask_files[0][0])\n",
    "fmri_glm.subject_label = meta['dim1'][sub_idx]\n",
    "confounds = pd.read_csv(conf_files[con_idx][sub_idx], sep='\\t')\n",
    "confounds = confounds[confounds_relevant]\n",
    "confounds.index = frame_times # Standard time representation (in seconds)\n",
    "\n",
    "# Setup events\n",
    "resp_type = beh[sub_idx, con_idx, :, meta['dim4'].index('response')]\n",
    "onset_dec = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_dec')] \n",
    "onset_res = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_dec')] + \\\n",
    "            beh[sub_idx, con_idx, :, meta['dim4'].index('rt')]\n",
    "onset_out = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_out')]\n",
    "\n",
    "modulation_wcor = modulations_perr[sub_idx, con_idx, resp_type != 0]\n",
    "modulation_exvl = modulations_perr[sub_idx, con_idx, resp_type != 0]\n",
    "modulation_perr = modulations_perr[sub_idx, con_idx, resp_type != 0]\n",
    "\n",
    "# #---> choice phase regressors\n",
    "# reg_lbp = Regressor('lbp', frame_times, onset_dec[resp_type==-1])\n",
    "# reg_rbp = Regressor('rbp', frame_times, onset_dec[resp_type==1])\n",
    "# reg_miss = Regressor('miss', frame_times, onset_dec[resp_type==0])\n",
    "# reg_epw = Regressor(\n",
    "#     'epw', \n",
    "#     frame_times, \n",
    "#     onset_dec_phase[resp_type != 0],\n",
    "#     duration=beh[sub_idx, con_idx, resp_type != 0, meta['dim4'].index('rt')],\n",
    "#     modulation=epw_regressor\n",
    "# )\n",
    "# reg_erew = Regressor(\n",
    "#     'erew', \n",
    "#     frame_times, \n",
    "#     onset_dec_phase[resp_type != 0],\n",
    "#     duration=beh[sub_idx, con_idx, resp_type != 0, meta['dim4'].index('rt')],\n",
    "#     modulation=erew_regressor\n",
    "# )\n",
    "\n",
    "# #---> outcome phase regressors\n",
    "# reg_pe_full = Regressor(\n",
    "#     'pe_full', frame_times, onset_out[resp_type != 0], \n",
    "#     modulation=pe_regressor\n",
    "# )\n",
    "# reg_pe_sign = Regressor(\n",
    "#     'pe_sign', frame_times, onset_out[resp_type != 0],\n",
    "#     modulation=np.sign(pe_regressor)\n",
    "# )\n",
    "# reg_pe_surp = Regressor(\n",
    "#     'pe_surp', frame_times, onset_out[resp_type != 0], \n",
    "#     modulation=np.abs(pe_regressor)\n",
    "# )\n",
    "# reg_pe_miss = Regressor(\n",
    "#     'pe_miss', frame_times, onset_out[resp_type == 0]\n",
    "# )\n",
    "\n",
    "############################################################################\n",
    "############### paste rest of the code from below cells here ###############\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------#\n",
    "#                            glm_utils.py                                      #\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from nistats.design_matrix import make_first_level_design_matrix\n",
    "\n",
    "class Regressor():\n",
    "    '''Implements representation of the single GLM regressor.\n",
    "    \n",
    "    Allows for conversion of regressor described as number of onsets and \n",
    "    optionally magnitude modulations into estimated BOLD timecourse through \n",
    "    make_first_level_design_matrix function from Nistats. Useful in situations\n",
    "    where there are mutliple parametrically modulated regressors. Automatically\n",
    "    handled both cases of unmodulated and modulated regressors.\n",
    "    ''' \n",
    "    def __init__(self, name, frame_times, onset, \n",
    "                 duration=None, modulation=False):\n",
    "        '''\n",
    "        Args:\n",
    "            name (str): Name of the regressor.\n",
    "            frame_times (array of shape (n_frames,)):\n",
    "                The timing of acquisition of the scans in seconds.\n",
    "            onset (np.array): \n",
    "                Specifies the start time of each event in seconds.\n",
    "            duration (np.array, optional): \n",
    "                Duration of each event in seconds. Defaults duration is set to \n",
    "                0 (impulse function).\n",
    "            modulation (np.array, optional): \n",
    "                Parametric modulation of event amplitude. Before convolution \n",
    "                regressor is demeaned. \n",
    "        '''\n",
    "        self._name = name\n",
    "        self._onset = onset.copy()\n",
    "        self._frame_times = frame_times.copy()\n",
    "        self._n_events = len(onset)\n",
    "        \n",
    "        if modulation is not False:\n",
    "            if modulation.shape != onset.shape:\n",
    "                raise ValueError(\n",
    "                    'onset and modulation have to be the same shape, but '\\\n",
    "                    '{} and {} were passed'.format(modulation.shape, onset.shape)\n",
    "                )\n",
    "        else:\n",
    "            self._modulation = False\n",
    "        self._modulation = modulation\n",
    "        \n",
    "        if duration is None:\n",
    "            self._duration = np.zeros(onset.shape)\n",
    "        else:\n",
    "            if duration.shape != onset.shape:\n",
    "                raise ValueError(\n",
    "                    'onset and duration have to be the same shape, but '\\\n",
    "                    '{} and {} were passed'.format(duration.shape, onset.shape)\n",
    "                )\n",
    "            self._duration = duration\n",
    "            \n",
    "        self._dm_column = self._create_dm_column()\n",
    "        \n",
    "    @property\n",
    "    def is_empty(self):\n",
    "        return (self._onset.size == 0)\n",
    "            \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "                \n",
    "    @property\n",
    "    def dm_column(self):\n",
    "        return self._dm_column\n",
    "    \n",
    "    def _create_dm_column(self):\n",
    "        '''Create column of design matrix corresponding to regressor modulation.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "                \n",
    "        Returns: (pd.DataFrarme)\n",
    "            Regressor time-course convolved with HRF.        \n",
    "        '''\n",
    "        events_dict = {\n",
    "            'onset': self._onset,\n",
    "            'duration': self._duration,\n",
    "            'trial_type': np.ones(self._n_events)\n",
    "        } \n",
    "\n",
    "        if self._modulation is not False:\n",
    "            events_dict['modulation'] = self._modulation\n",
    "\n",
    "        events = pd.DataFrame(events_dict        )\n",
    "        events.loc[:, \"trial_type\"] = self.name\n",
    "        \n",
    "        if self._modulation is not False:\n",
    "            events['modulation'] -= events['modulation'].mean()\n",
    "        \n",
    "        dm = make_first_level_design_matrix(self._frame_times, events, drift_model=None)\n",
    "        dm = dm.drop('constant', axis=1)\n",
    "\n",
    "        return dm\n",
    "    \n",
    "    def plot_regressor(self, color='r') -> None:\n",
    "        '''Plots BOLD timecourse for regressors:\n",
    "        \n",
    "        Args:\n",
    "            color: Plot line color.\n",
    "        '''\n",
    "        fig, ax = plt.subplots(facecolor='w', figsize=(25, 3))\n",
    "\n",
    "        ax.plot(self._dm_column, color)\n",
    "        ax.set_xlim(0, np.max(self._frame_times))\n",
    "        ax.set_xlabel('Time [s]')\n",
    "        ax.set_ylabel('est. BOLD')\n",
    "        ax.grid()\n",
    "        \n",
    "    @classmethod\n",
    "    def corrcoef(cls, reg1, reg2):\n",
    "        '''Return correlation between two regressors'''\n",
    "        \n",
    "        rval = np.corrcoef(\n",
    "            reg1.dm_column.values.T, \n",
    "            reg2.dm_column.values.T\n",
    "        )\n",
    "        \n",
    "        return rval[0,1]\n",
    "\n",
    "def my_make_first_level_design_matrix(regressors: list, confounds):\n",
    "    '''Turn arbitrary number of regressors and confound table int design matrix.\n",
    "\n",
    "    Args:\n",
    "        regressors: list of Regressor objects\n",
    "        confounds: pd.DataFrame with confounds\n",
    "\n",
    "    Note:\n",
    "        Index of confounds should reflect frame times in secods and should match\n",
    "        regressors _frame_times.\n",
    "\n",
    "    Returns (2-tuple):\n",
    "        Final GLM design matrix as DataFrame and dictionary with condition\n",
    "        contrast vectors for all specifified regressors.\n",
    "    '''\n",
    "    regressors = [r for r in regressors if r.is_empty == False]\n",
    "    \n",
    "    add_regs = pd.concat(\n",
    "        [r.dm_column for r in regressors] + [confounds], axis=1, sort=False\n",
    "    )\n",
    "    add_reg_names = [r.name for r in regressors] + list(confounds.columns)\n",
    "\n",
    "    for ft1, ft2 in combinations([r._frame_times for r in regressors] +\n",
    "                                 [np.array(confounds.index)], 2):\n",
    "        if not np.array_equal(ft1, ft2):\n",
    "            raise ValueError(f'regressors frame_times not matching')\n",
    "\n",
    "    # Create design matrix\n",
    "    dm = make_first_level_design_matrix(\n",
    "        frame_times=regressors[0]._frame_times,\n",
    "        add_regs=add_regs,\n",
    "        add_reg_names=add_reg_names\n",
    "        )\n",
    "\n",
    "    # Create condition vectors for all regressors of interest\n",
    "    conditions = {r.name: np.zeros(dm.shape[1]) for r in regressors}\n",
    "    for condition_name in conditions:\n",
    "        conditions[condition_name][list(dm.columns).index(condition_name)] = 1\n",
    "\n",
    "    return (dm, conditions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected probability of winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm, conditions = my_make_first_level_design_matrix(\n",
    "    [reg_lbp, reg_rbp, reg_epw], confounds)\n",
    "\n",
    "# Fit GLM\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=dm)\n",
    "\n",
    "# Define contrast\n",
    "conditions['epw']\n",
    "\n",
    "# Compute statistical map and save it\n",
    "z_map = fmri_glm.compute_contrast(\n",
    "    conditions['epw'],\n",
    "    stat_type='t')\n",
    "\n",
    "z_map_fname = f\"sub-{meta['dim1'][sub_idx]}_\" + \\\n",
    "              f\"task-prl{meta['dim2'][con_idx]}_desc-epw_tmap\"\n",
    "# nib.save(z_map, os.path.join(out_dir_epw, z_map_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Button press contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm, conditions = my_make_first_level_design_matrix(\n",
    "    [reg_lbp, reg_rbp, reg_miss], confounds)\n",
    "\n",
    "# Fit GLM\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=dm)\n",
    "\n",
    "# Define contrast\n",
    "left_minus_right = conditions['lbp'] - conditions['rbp']\n",
    "\n",
    "# Compute statistical map and save it\n",
    "z_map = fmri_glm.compute_contrast(\n",
    "    left_minus_right,\n",
    "    stat_type='t')\n",
    "\n",
    "z_map_fname = f\"sub-{meta['dim1'][sub_idx]}_\" + \\\n",
    "              f\"task-prl{meta['dim2'][con_idx]}_desc-buttonpress_tmap\"\n",
    "# nib.save(z_map, os.path.join(out_dir_btn, z_map_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm, conditions = my_make_first_level_design_matrix(\n",
    "    [reg_lbp, reg_rbp, reg_miss, reg_pe_full, reg_pe_miss],\n",
    "    confounds\n",
    ")\n",
    "\n",
    "# Fit GLM\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=dm)\n",
    "\n",
    "# Compute statistical map and save it\n",
    "z_map = fmri_glm.compute_contrast(\n",
    "    conditions['pe_full'],\n",
    "    stat_type='t')\n",
    "\n",
    "z_map_fname = f\"sub-{meta['dim1'][sub_idx]}_\" + \\\n",
    "              f\"task-prl{meta['dim2'][con_idx]}_desc-pefull_tmap\"\n",
    "# nib.save(z_map, os.path.join(out_dir_pefull, z_map_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction error sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm, conditions = my_make_first_level_design_matrix(\n",
    "    [reg_lbp, reg_rbp, reg_miss, reg_pe_sgn, reg_pe_miss],\n",
    "    confounds\n",
    ")\n",
    "\n",
    "# Fit GLM\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=dm)\n",
    "\n",
    "# Compute statistical map and save it\n",
    "z_map = fmri_glm.compute_contrast(\n",
    "    conditions['pe_sgn'],\n",
    "    stat_type='t')\n",
    "\n",
    "z_map_fname = f\"sub-{meta['dim1'][sub_idx]}_\" + \\\n",
    "              f\"task-prl{meta['dim2'][con_idx]}_desc-pesign_tmap\"\n",
    "# nib.save(z_map, os.path.join(out_dir_pesign, z_map_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction error absolute value (surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm, conditions = my_make_first_level_design_matrix(\n",
    "    [reg_lbp, reg_rbp, reg_miss, reg_pe_sur, reg_pe_miss],\n",
    "    confounds\n",
    ")\n",
    "\n",
    "# Fit GLM\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=dm)\n",
    "\n",
    "# Define contrast\n",
    "conditions['pe_sur']\n",
    "\n",
    "# Compute statistical map and save it\n",
    "z_map = fmri_glm.compute_contrast(\n",
    "    conditions['pe_sur'],\n",
    "    stat_type='t')\n",
    "\n",
    "z_map_fname = f\"sub-{meta['dim1'][sub_idx]}_\" + \\\n",
    "              f\"task-prl{meta['dim2'][con_idx]}_desc-pesurp_tmap\"\n",
    "# nib.save(z_map, os.path.join(out_dir_pesurp, z_map_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore correlation between regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between expected probability of winning and expected value\n",
    "reg_corr = np.zeros((n_subjects, n_conditions))\n",
    "\n",
    "for sub_idx in range(n_subjects):\n",
    "    for con_idx in range(n_conditions):\n",
    "\n",
    "        # Load decision phase regressors\n",
    "        onset_dec = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_dec')] + \\\n",
    "            beh[sub_idx, con_idx, :, meta['dim4'].index('rt')]\n",
    "        resp_type = beh[sub_idx, con_idx, :, meta['dim4'].index('response')]\n",
    "        epw_regressor = epw_regressors[sub_idx, con_idx, resp_type != 0]\n",
    "        erew_regressor = erew_regressors[sub_idx, con_idx, resp_type != 0]\n",
    "        \n",
    "        # Grab correlation between decision phase regressors\n",
    "        reg_epw = Regressor('epw', frame_times, onset_dec[resp_type!=0], \n",
    "                            modulation=epw_regressor)\n",
    "        reg_erew = Regressor('erew', frame_times, onset_dec[resp_type!=0],\n",
    "                             modulation=erew_regressor)\n",
    "        reg_corr[sub_idx, con_idx] = Regressor.corrcoef(reg_epw, reg_erew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
