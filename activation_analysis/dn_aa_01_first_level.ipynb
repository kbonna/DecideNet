{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First level GLM analysis\n",
    "\n",
    "This script performs subject level modeling of BOLD response. Script features: \n",
    "- reads BIDS dataset, loads imaging files, confounds and parametric modulations\n",
    "- for each subject and session:\n",
    "    - creates parametrically modulated regressors\n",
    "    - creates full first level GLM\n",
    "    - estimate and save statistical maps for predefined contrasts\n",
    "\n",
    "---\n",
    "**Last update**: 12.02.2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import namedtuple\n",
    "\n",
    "import nibabel as nib\n",
    "from bids import BIDSLayout\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, show\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.reporting import plot_design_matrix, make_glm_report\n",
    "from nistats.thresholding import map_threshold\n",
    "from nistats.design_matrix import make_first_level_design_matrix\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = os.path.join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.behavioral_models import load_behavioral_data                    \n",
    "from dn_utils.glm_utils import Regressor, my_make_first_level_design_matrix\n",
    "from dn_utils.plotting import plot_correlation_between_regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save first-level output\n",
    "path_out = os.path.join(path_root, \n",
    "                        'data/main_fmri_study/derivatives/nistats/first_level_output')\n",
    "os.makedirs(path_out, exist_ok=True)\n",
    "\n",
    "# Load behavioral data\n",
    "path_beh = os.path.join(path_root, 'data/main_fmri_study/sourcedata/behavioral')\n",
    "beh, meta = load_behavioral_data(path=path_beh)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query neuroimaging dataset\n",
    "\n",
    "Using BIDSLayout object query BIDS dataset to pull out necessary files.\n",
    "- `anat_files`: sorted list of preprocessed T1w images\n",
    "- `fmri_files`: list of two lists containing sorted (by subject number) paths to imaging files, first list corresponds to reward condition of PRL task and second list corresponds to punishment condition of PRL task\n",
    "- `conf_files`: list of two lists containing sorted (by subject number) paths to confound files\n",
    "- `mask_files`: brain mask files for fmri sequencnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bids = os.path.join(path_root, 'data/main_fmri_study')\n",
    "\n",
    "layout = BIDSLayout(\n",
    "    root=path_bids,\n",
    "    derivatives=True,\n",
    "    validate=True,\n",
    "    index_metadata=False\n",
    ")\n",
    "\n",
    "anat_filter = {\n",
    "    \"extension\": [\".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"suffix\": \"T1w\",\n",
    "    \"desc\": \"preproc\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "fmri_filter = {\n",
    "    \"extension\": [\".nii\", \".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"suffix\": \"bold\",\n",
    "    \"desc\": \"preproc\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "conf_filter = {\n",
    "    \"extension\": \"tsv\",\n",
    "    \"desc\": \"confounds\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "mask_filter = {\n",
    "    \"extension\": [\".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"desc\": \"brain\",\n",
    "    \"suffix\": \"mask\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "anat_files = layout.get(**anat_filter)\n",
    "\n",
    "fmri_files, conf_files, mask_files = [], [], []\n",
    "\n",
    "for task_dict in [{\"task\": \"prlrew\"}, {\"task\": \"prlpun\"}]:\n",
    "    fmri_filter.update(task_dict)\n",
    "    conf_filter.update(task_dict)\n",
    "    mask_filter.update(task_dict)\n",
    "    fmri_files.append(layout.get(**fmri_filter))\n",
    "    conf_files.append(layout.get(**conf_filter))\n",
    "    mask_files.append(layout.get(**mask_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load task modulations\n",
    "Here, modulations for model-based fMRI are downloaded. Two modulations apply to decision phase (expected probability of choosing correct box `wcor` and Pascalian expected value `exvl`) and one modulation apply to outcome phase (probabilistic prediction error `perr`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_modulations = os.path.join(path_root, \n",
    "                                'data/main_fmri_study/derivatives/nistats/modulations')\n",
    "\n",
    "# Load parametric modulations\n",
    "modulations_wcor = np.load(os.path.join(path_modulations,'modulations_wcor.npy'))\n",
    "modulations_exvl = np.load(os.path.join(path_modulations,'modulations_exvl.npy'))\n",
    "modulations_perr = np.load(os.path.join(path_modulations,'modulations_perr.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single subject analysis\n",
    "\n",
    "Here, first level GLM analysis is performed for each subject and task condition. `FirstLevelModel` instance is created initialized with proper GLM settings (hemodynamic response function, drift and noise model, high pass filter, smoothing kernel). Then, for each imaging sequence following steps are applied:\n",
    "1. Data files are loaded (T1w anatomical image, EPI sequence, brain mask for EPI sequence, confounds table.\n",
    "2. Task events onsets are loaded.\n",
    "3. Different task regressors are created. Some of them are parametrically modulated using subject-specific modulations.\n",
    "4. First level design matrix is created. Design matrix consists of task regressors, drift regressors, confound regressors.\n",
    "5. GLM parameters are estimated.\n",
    "6. Statistical maps for specified contrasts of interest are calculated and saved within `derivatives/nistats/first_level_output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GLM\n",
    "fmri_glm = FirstLevelModel(\n",
    "    t_r=2,\n",
    "    hrf_model='spm',\n",
    "    drift_model='cosine',\n",
    "    noise_model='ar1',\n",
    "    high_pass=0.0078125, \n",
    "    standardize=True,\n",
    "    smoothing_fwhm=6)\n",
    "\n",
    "# Name of relevant confounds\n",
    "confounds_relevant = [col for col in pd.read_csv(conf_files[0][0], sep='\\t').columns \n",
    "                      if 'rot' in col or 'trans' in col]\n",
    "\n",
    "# Times of image acquisition in seconds\n",
    "n_scans, t_r = 730, 2\n",
    "frame_times = np.arange(n_scans) * t_r\n",
    "\n",
    "# Useful object for representing contrasts\n",
    "MyContrast = namedtuple('Contrast', 'name contrast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model specification\n",
    "\n",
    "#### Task regressors\n",
    "\n",
    "|   phase  | name               |    variable    |    onset    | duration |    modulation   |\n",
    "|:--------:|--------------------|:--------------:|:-----------:|:--------:|:---------------:|\n",
    "| decision | decision onset     |  `reg_dec_ons` | `onset_dec` |     0    |       None      |\n",
    "| response | left button press  |  `reg_res_lbp` | `onset_res` |     0    |       None      |\n",
    "|          | right button press |  `reg_res_rbp` | `onset_res` |     0    |       None      |\n",
    "|          | too late feedback  | `reg_res_miss` | `onset_isi` |     0    |       None      |\n",
    "|  outcome | outcome onset      |  `reg_out_ons` | `onset_out` |     0    |       None      |\n",
    "|          | prediction error   | `reg_out_perr` | `onset_out` |     0    | `perr_demeaned` |\n",
    "\n",
    "#### Confounds\n",
    "\n",
    "As confounds, we included 24 motion parameters (6 rigid body parameters, their second power, their derivatives, second power of their derivatives).\n",
    "\n",
    "#### Drift model\n",
    "\n",
    "We included standard `nistats` cosine model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_idx in range(n_subjects):\n",
    "    for con_idx in range(n_conditions):\n",
    "\n",
    "        # Load subject data\n",
    "        anat_img = nib.load(anat_files[sub_idx])\n",
    "        fmri_img = nib.load(fmri_files[con_idx][sub_idx])\n",
    "        fmri_glm.mask = nib.load(mask_files[0][0])\n",
    "        fmri_glm.subject_label = meta['dim1'][sub_idx]\n",
    "        confounds = pd.read_csv(conf_files[con_idx][sub_idx], sep='\\t')\n",
    "        confounds = confounds[confounds_relevant]\n",
    "        confounds.index = frame_times # Standard time representation (in seconds)\n",
    "\n",
    "        # Setup events\n",
    "        resp_type = beh[sub_idx, con_idx, :, meta['dim4'].index('response')]\n",
    "        onset_dec = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_dec')] \n",
    "        onset_res = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_dec')] + \\\n",
    "                    beh[sub_idx, con_idx, :, meta['dim4'].index('rt')]\n",
    "        onset_out = beh[sub_idx, con_idx, :, meta['dim4'].index('onset_out')]\n",
    "\n",
    "        modulation_wcor = modulations_perr[sub_idx, con_idx, resp_type != 0]\n",
    "        modulation_exvl = modulations_perr[sub_idx, con_idx, resp_type != 0]\n",
    "        modulation_perr = modulations_perr[sub_idx, con_idx, resp_type != 0]\n",
    "\n",
    "        modulation_wcor_demeaned = modulation_wcor - np.mean(modulation_wcor)\n",
    "        modulation_exvl_demeaned = modulation_exvl - np.mean(modulation_exvl)\n",
    "        modulation_perr_demeaned = modulation_perr - np.mean(modulation_perr)\n",
    "\n",
    "        # Create regressors\n",
    "        reg_res_lbp = Regressor('res_lbp', frame_times, onset_res[resp_type==-1])\n",
    "        reg_res_rbp = Regressor('res_rbp', frame_times, onset_res[resp_type==1])\n",
    "        reg_res_miss = Regressor('res_miss', frame_times, onset_dec[resp_type==0] + 2)\n",
    "\n",
    "        reg_dec_ons = Regressor('dec_ons', frame_times, onset_dec[resp_type != 0])\n",
    "        reg_dec_tillres = Regressor(\n",
    "            'dec_tillres', frame_times, onset_dec[resp_type != 0],\n",
    "            duration=beh[sub_idx, con_idx, resp_type != 0, meta['dim4'].index('rt')])\n",
    "        reg_dec_wcor = Regressor(\n",
    "            'dec_wcor', frame_times, onset_dec[resp_type != 0],\n",
    "            duration=beh[sub_idx, con_idx, resp_type != 0, meta['dim4'].index('rt')],\n",
    "            modulation = modulation_wcor_demeaned)\n",
    "\n",
    "        reg_out_ons = Regressor('out_ons', frame_times, onset_out[resp_type != 0])\n",
    "        reg_out_miss = Regressor('out_miss', frame_times, onset_out[resp_type == 0]) \n",
    "        reg_out_perr = Regressor('out_perr', frame_times, onset_out[resp_type != 0], \n",
    "            modulation = modulation_perr_demeaned)\n",
    "\n",
    "        regressors = [reg_dec_ons, \n",
    "                      reg_res_lbp, reg_res_rbp, reg_res_miss, \n",
    "                      reg_out_ons, reg_out_perr]\n",
    "\n",
    "        # Create design matrix\n",
    "        dm, conditions = my_make_first_level_design_matrix(regressors)\n",
    "\n",
    "        # Fit GLM\n",
    "        fmri_glm = fmri_glm.fit(fmri_img, confounds=confounds, design_matrices=dm)\n",
    "\n",
    "        # Define contrasts\n",
    "        contrasts = []\n",
    "        contrasts.append(MyContrast('res_lbp_minus_rbp', \n",
    "                                    conditions['res_lbp'] - conditions['res_rbp']))\n",
    "        contrasts.append(MyContrast('out_ons', conditions['out_ons']))\n",
    "        contrasts.append(MyContrast('out_perr', conditions['out_perr']))\n",
    "\n",
    "        # Compute statistical maps and save it\n",
    "        for contrast in contrasts:\n",
    "            stat_map = fmri_glm.compute_contrast(\n",
    "                contrast.contrast, \n",
    "                stat_type='t',\n",
    "                output_type='z_score'\n",
    "            )\n",
    "\n",
    "            stat_map_fname = f\"sub-{meta['dim1'][sub_idx]}_task-prl{meta['dim2'][con_idx]}_statmap\"\n",
    "            os.makedirs(os.path.join(path_out, contrast.name), exist_ok=True)\n",
    "\n",
    "            nib.save(stat_map, os.path.join(path_out, contrast.name, stat_map_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
