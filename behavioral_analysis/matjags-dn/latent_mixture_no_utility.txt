model {

## Generative model #######################################################
for (i in 1:nSubjects){
    for (j in 1:nConditions){

        # Single learning rate
        vl_s[i, j, 1]   = .5
        vr_s[i, j, 1]   = .5

        # Double learning rate
        vl_d[i, j, 1]   = .5
        vr_d[i, j, 1]   = .5
   
        # Choose submodel
        vl[i, j, 1] = ifelse(z[i]==1, vl_s[i, j, 1], vl_d[i, j, 1]) 
        vr[i, j, 1] = ifelse(z[i]==1, vr_s[i, j, 1], vr_d[i, j, 1])

        # Generate first response
        eul[i, j, 1]    = vl[i, j, 1] * xl[i, j, 1]         # expected utility for left box
        eur[i, j, 1]    = vr[i, j, 1] * xr[i, j, 1]         # expected utility for right box
        theta[i, j, 1]  = (1) / (1 + exp(beta[i] * (eul[i, j, 1] - eur[i, j, 1])))
        resp[i, j, 1]   ~ dbern(theta[i, j, 1])             # generated response

        for (t in 2:nTrials){

            # Single learning rate update
            vl_s[i, j, t]     = ifelse(
                rwd[i, j, t-1] == 0,                        # left rewarded in previous trial 
                vl_s[i, j, t-1] + alpha[i] * (1 - vl_s[i, j, t-1]), 
                vl_s[i, j, t-1] + alpha[i] * (0 - vl_s[i, j, t-1]))
            vr_s[i, j, t]     = ifelse(                       
                rwd[i, j, t-1] == 1,                        # right rewarded in previous trial
                vr_s[i, j, t-1] + alpha[i] * (1 - vr_s[i, j, t-1]), 
                vr_s[i, j, t-1] + alpha[i] * (0 - vr_s[i, j, t-1]))

            # Double learning rate update
            vl_d[i, j, t]     = ifelse(
                rwd[i, j, t-1] == 0,                   
                vl_d[i, j, t-1] + alpha_d[i, j] * (1 - vl_d[i, j, t-1]), 
                vl_d[i, j, t-1] + alpha_d[i, j] * (0 - vl_d[i, j, t-1]))
            vr_d[i, j, t]     = ifelse(                       
                rwd[i, j, t-1] == 1,                   
                vr_d[i, j, t-1] + alpha_d[i, j] * (1 - vr_d[i, j, t-1]), 
                vr_d[i, j, t-1] + alpha_d[i, j] * (0 - vr_d[i, j, t-1]))

            # Choose submodel
            vl[i, j, t] = ifelse(z[i]==1, vl_s[i, j, t], vl_d[i, j, t]) 
            vr[i, j, t] = ifelse(z[i]==1, vr_s[i, j, t], vr_d[i, j, t])

            # Recalculate utilities
            eul[i, j, t]    = vl[i, j, t] * xl[i, j, t]                                 # expected utility for left box
            eur[i, j, t]    = vr[i, j, t] * xr[i, j, t]                                 # expected utility for right box
            tempth[i, j, t] = 1 / (1 + exp(beta[i] * (eul[i, j, t] - eur[i, j, t])));   # choice probability
            theta[i, j, t]  = max(0.000001, min(0.999999, tempth[i, j, t]))             # ensure 0 < cp < 1
            resp[i, j, t]   ~ dbern(theta[i, j, t])                                     # generated response


        }
    }
}


## Priors #################################################################

#indicator variables
#the model indicator variable z can take on any value from 1:n, and is subject to two stochastic processes, to prevent getting stuck
#the n values map onto just 3 models, and is simply a means of obtaining parameter expansion for the model indication
for (m in 1:2){
    pz[m]   = 1/2
}
for (i in 1:nSubjects){    
px_z1[i]    ~ dcat(pz[])                                 #parameter expansion variable for z, takes on integers 1:n with equal probability
px_z2[i]    ~ dcat(pz[])                                 #parameter expansion variable for z, takes on integers 1:n with equal probability
delta_z1[i] = px_z2[i]-1                                 #parameter expansion variable for z, takes on integers 0:n-1 with equal probability
sum_z[i]    = px_z1[i]+delta_z1[i]                       #sum takes on integers 1:2*n -1 with equal probability
z[i]        = (sum_z[i] - (2 * trunc(sum_z[i]/2))) + 1   #modulo n, adding 1 to return to values 1 to 12 
}    

#behavioral parameters
for (i in 1:nSubjects){
    for (j in 1:nConditions){
        alpha_d[i, j] ~ dbeta(a_alpha_d[j], b_alpha_d[j])
    }
    alpha[i]    ~ dbeta(a_alpha, b_alpha)
    beta[i]     ~ dlnorm(mu_beta, sigma_beta)

}

## Hyperpriors ############################################################
a_alpha         ~ dunif(1, 10)
b_alpha         ~ dunif(1, 10)
for (j in 1:nConditions){
    a_alpha_d[j]~ dunif(1, 10)
    b_alpha_d[j]~ dunif(1, 10)
    }
mu_beta         ~ dunif(-2.3, 3.4)
sigma_beta      ~ dunif(0.01, 1.6) 

}