model {

### GENERATIVE MODEL
for (j in 1:nConditions){
    for (i in 1:nSubjects){

        # Initial values
        vl[j, i, 1]  = .5
        vr[j, i, 1]  = .5
        ul[j, i, 1]  = ifelse(j==2, -gamma[i]*(magnl[j, i, 1]^delta[i]), magnl[j, i, 1]^delta[i])
        ur[j, i, 1]  = ifelse(j==2, -gamma[i]*(magnr[j, i, 1]^delta[i]), magnr[j, i, 1]^delta[i])
        pl[j, i, 1]  = exp(beta[i] * vl[j, i, 1] * ul[j, i, 1])
        pr[j, i, 1]  = exp(beta[i] * vr[j, i, 1] * ur[j, i, 1])
        p[j, i, 1]   = pr[j, i, 1] / (pl[j, i, 1] + pr[j, i, 1])
        choice[j, i, 1] ~ dbern(p[j, i, 1])

        for (t in 2:nTrials){

            # Update probabilities
            vl[j, i, t] = ifelse(rwd[j, i, t-1]==0, vl[j, i, t-1]+alpha[i]*(1-vl[j, i, t-1]), vl[j, i, t-1]+alpha[i]*(0-vl[j, i, t-1]))
            vr[j, i, t] = ifelse(rwd[j, i, t-1]==1, vr[j, i, t-1]+alpha[i]*(1-vr[j, i, t-1]), vr[j, i, t-1]+alpha[i]*(0-vr[j, i, t-1]))

            # Calculate utilities
            ul[j, i, t]  = ifelse(j==2, -gamma[i]*(magnl[j, i, t]^delta[i]), magnl[j, i, t]^delta[i])
            ur[j, i, t]  = ifelse(j==2, -gamma[i]*(magnr[j, i, t]^delta[i]), magnr[j, i, t]^delta[i])

            # Calculate utility and choice probability
            pl[j, i, t]  = exp(beta[i] * vl[j, i, t] * ul[j, i, t])
            pr[j, i, t]  = exp(beta[i] * vr[j, i, t] * ur[j, i, t])
            p[j, i, t]   = pr[j, i, t] / (pl[j, i, t] + pr[j, i, t])

            # Observed choice
            choice[j, i, t] ~ dbern(p[j, i, t])
        }
    }
}

### Hyper-priors 
alpha_mu ~ dbeta(2, 5)
alpha_std ~ dnorm(0, .3)T(0, )

### Priors
for (i in 1:nSubjects){
    # Individual learning rate
    a[i]     = -(alpha_mu * (alpha_std^2 + alpha_mu^2 - alpha_mu))/alpha_std^2
    b[i]     = (alpha_mu * (alpha_std^2 + alpha_mu^2 - alpha_mu))*(alpha_mu-1)/alpha_std^2
    alpha[i] ~ dbeta(a[i], b[i])
    # Softmax inverse temperature
    beta[i]  ~ dnorm(1, 2)T(0, )    
    # Loss aversion
    gamma[i] ~ dnorm(1, 2)T(0, )
    # Risk aversion
    delta[i] ~ dunif(0, 1)
}

}