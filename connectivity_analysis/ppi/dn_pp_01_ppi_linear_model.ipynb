{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPI General Linear Model\n",
    "\n",
    "Here, PPI network construction is performed by evaluating multiple linear models and extracting regressors beta weights. PPI linear model takes form: \n",
    "\n",
    "$$y=\\beta_0\n",
    "+\\beta_1\\cdot x_{physio}\n",
    "+\\beta_2\\cdot x_{out\\_ons}\n",
    "+\\beta_3\\cdot x_{out\\_perr}\n",
    "+\\beta_4\\cdot x_{PPI:out\\_ons}\n",
    "+\\beta_5\\cdot x_{PPI:out\\_perr}\n",
    "+\\beta_6\\cdot x_{dec\\_ons}\n",
    "+\\beta_7\\cdot x_{dec\\_miss}\n",
    "+\\beta_8\\cdot x_{dec\\_wcor}\n",
    "+\\beta_9\\cdot x_{res\\_lbp}\n",
    "+\\beta_{10}\\cdot x_{res\\_rbp}\n",
    "+\\beta_{11}\\cdot x_{res\\_miss}\n",
    "+\\beta_{12}\\cdot x_{out\\_off}$$\n",
    "\n",
    "Detailed regressors description:\n",
    "\n",
    "| Regressor | Type | Description | Event Duration\n",
    "|:--:|----|----|----|\n",
    "| `y` | physiological | BOLD signal from target region | – |\n",
    "| | | | |\n",
    "| `physio` | physiological | BOLD signal from seed region | – |\n",
    "| `out_ons` | psychological | outcome phase onset | `t_event_psycho` |\n",
    "| `out_perr` | psychological | outcome phase onset parametrically modulated with prediction error | `t_event_psycho` |\n",
    "| `ppi_out_ons` | interaction | `out_ons` point-by-point multiplied with <br />deconvolved seed timeseries, reconvolved with HRF | `t_event_ppi` \n",
    "| **`ppi_out_perr`** | interaction | `out_perr` point-by-point multiplied with <br />deconvolved seed timeseries, reconvolved with HRF | `t_event_ppi` |\n",
    "| `dec_ons` | psychological | decision phase onset | `t_event_psycho` |\n",
    "| `dec_miss` | psychological | decision phase onset for trials with missing response | `t_event_psycho` |\n",
    "| `dec_wcor` | psychological | decision phase onset parametrically modulated with expected probability of being correct | `t_event_psycho` |\n",
    "| `res_lbp` | psychological | left button press onset | `t_event_psycho` |\n",
    "| `res_rbp` | psychological | right button press onset | `t_event_psycho` |\n",
    "| `res_miss` | psychological | onset of isi phase for trials with missing response | `t_event_psycho` |\n",
    "| `out_off` | psychological | outcome phase offset | `t_event_psycho` |\n",
    "| `intercept` | other | intercept for linear model | – |\n",
    "\n",
    "Each type of regressor was calculated differently: \n",
    "- **physiological regressors**: BOLD signals extracted using `NiftiSpheresMasker`. Before extraction confounds (24 head motion parameters, CSF and WM signals, squares, temporal derivatives and squares of temporal derivatives) and low-frequency drift were removed and signal was high pass-filtered (128s), \n",
    "- **psychological regressors**: task events convolved with canonical HRF using `compute_regressor` function from `nistats.hemodynamic_models` wrapped in custom `Regressor` class for consistent treating standard and parametrically modulated regressor, \n",
    "- **interaction (PPI) regressors**: first, ROIs timeseries were extracted with detrending and high-pass filtering. Then they were deconvolved using spm fuction for parameter estimation Bayes `spm_PEB.m`. Deconvolved and upsampled (by default 16 times) ROI timeseries were point-by-point multiplied with upsampled and demeaned task events timeseries to create interaction regressor in neural space. Finally, these interaction regressors were reconvolved with HRF and downsampled to create PPI regressors in BOLD space.\n",
    "\n",
    "---\n",
    "**Last update**: 09.12.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmb/Desktop/Neuroscience/Projects/BONNA_decide_net/code/dn_utils/glm_utils.py:13: FutureWarning: \n",
      "\n",
      " | Starting with Nilearn 0.7.0, all Nistats functionality has been incorporated into Nilearn's stats & reporting modules.\n",
      " | Nistats package will no longer be updated or maintained.\n",
      "\n",
      "  from nistats import design_matrix\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.regression.linear_model as sm\n",
    "from IPython.display import clear_output\n",
    "from scipy import io\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.behavioral_models import load_behavioral_data\n",
    "from dn_utils.glm_utils import (convolve, Regressor, upsampled_events,\n",
    "                                my_make_first_level_design_matrix)\n",
    "from dn_utils.plotting import plot_design_matrix, plot_regressors_correlation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beh.shape (32, 2, 110, 23)\n",
      "modulations_wcor.shape (32, 2, 110)\n",
      "modulations_perr.shape (32, 2, 110)\n",
      "timeseries_neural_aggregated.shape (32, 2, 11680, 30)\n",
      "timeseries_denoised_aggregated.shape (32, 2, 730, 30)\n",
      "downsamples.shape (730,)\n"
     ]
    }
   ],
   "source": [
    "# Directory for PPI analysis\n",
    "path_nistats = join(path_root, 'data/main_fmri_study/derivatives/nistats')\n",
    "path_out = join(path_root, 'data/main_fmri_study/derivatives/ppi')\n",
    "path_betamats = join(path_out, 'betamats')\n",
    "path_timeries = join(path_out, 'timeseries')\n",
    "path_parcellations = join(path_out, 'parcellations')\n",
    "\n",
    "# Load behavioral data\n",
    "path_beh = join(path_root, 'data/main_fmri_study/sourcedata/behavioral')\n",
    "beh, meta = load_behavioral_data(path=path_beh, verbose=False)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape\n",
    "\n",
    "# Load trial modulations\n",
    "path_modulations = join(path_nistats, 'modulations')\n",
    "modulations_wcor = np.load(join(path_modulations, 'modulations_wcor.npy'))\n",
    "modulations_perr = np.load(join(path_modulations, 'modulations_perr.npy'))\n",
    "\n",
    "# Load neural & BOLD timeseries\n",
    "data = io.loadmat(join(\n",
    "    path_timeries, \n",
    "    'timeseries_pipeline-24HMPCSFWM_atlas-meta2ROI_neural.mat'))                # !!!\n",
    "timeseries_neural_aggregated = data['timeseries_neural_aggregated']\n",
    "timeseries_denoised_aggregated = np.load(join(\n",
    "    path_timeries, \n",
    "    'timeseries_pipeline-24HMPCSFWM_atlas-metaROI_bold.npy'))\n",
    "downsamples = data['k'].flatten()\n",
    "\n",
    "# Load region labels\n",
    "df_rois = pd.read_csv(join(path_parcellations, 'meta_roi/meta_roi_table.csv'))\n",
    "roi_labels = list(df_rois['abbrev'] + ' ' + df_rois['hemisphere'])\n",
    "\n",
    "# Create directory for output\n",
    "atlas_name = 'meta2ROI'                                                         # !!!\n",
    "path_results = join(path_betamats, atlas_name)\n",
    "Path(path_results).mkdir(exist_ok=True)\n",
    "\n",
    "# Acquisition parameters\n",
    "_, _, n_volumes, n_rois = timeseries_denoised_aggregated.shape\n",
    "t_r = 2\n",
    "frame_times = np.arange(n_volumes) * t_r\n",
    "\n",
    "# Duration of phases\n",
    "t_dec, t_out = 1.5, 1.5\n",
    "\n",
    "# Upsampling rate for deconvolved signal\n",
    "sampling_rate = 1 / 16\n",
    "\n",
    "# Input data shape\n",
    "print('beh.shape', beh.shape)\n",
    "print('modulations_wcor.shape', modulations_wcor.shape)\n",
    "print('modulations_perr.shape', modulations_perr.shape)\n",
    "print('timeseries_neural_aggregated.shape', timeseries_neural_aggregated.shape)\n",
    "print('timeseries_denoised_aggregated.shape', timeseries_denoised_aggregated.shape)\n",
    "print('downsamples.shape', downsamples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings\n",
    "\n",
    "Here, all important PPI modelling setting are stored in `options` dictionary. Dictionary have keys:\n",
    "- `t_event_psycho`: duration of all psychological events (e.g. button press)\n",
    "- `t_event_ppi`: duration of psychological events for upsampled regressors\n",
    "- `binarize_perr`: set `False` if you want to use prediction error as a continuous variable, otherwise it will be binarized\n",
    "- `binarize_wcor`: set `False` if you want to use expected probability for side for being correct as a continuous varialbe, otherwise it will be binarized\n",
    "- `save_dm_plots`: set `True` if you want to store plot of each individal design matrix\n",
    "- `save_reg_corr_plots`: set `True` if you want to store plot of correlation between regressors\n",
    "- `regressors_model` list of all regressors included in model\n",
    "- `regressors_save` list of regressors for which beta estimates are saved (it has to be subset of `regressors_model`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic options\n",
    "options = {\n",
    "    'binarize_perr': False,\n",
    "    'binarize_wcor': False,\n",
    "    'save_dm_plots': False,\n",
    "    'save_reg_corr_plots': False\n",
    "}\n",
    "\n",
    "# Keys are all regressors (even miss regressors which some of participants may \n",
    "# not have)\n",
    "beta_colors = {\n",
    "    'physio': 'tab:red', \n",
    "    'out_ons': 'tab:blue',\n",
    "    'out_perr': 'tab:purple',\n",
    "    'ppi_out_ons': 'tab:green',\n",
    "    'ppi_out_perr': 'tab:orange',\n",
    "    'dec_ons': 'tab:blue',\n",
    "    'dec_miss': 'tab:blue',\n",
    "    'dec_wcor':'tab:purple',\n",
    "    'res_lbp': 'tab:blue',\n",
    "    'res_rbp': 'tab:blue',\n",
    "    'res_miss': 'tab:blue',\n",
    "    'out_off': 'tab:blue',\n",
    "    'reg_intercept': 'tab:gray'\n",
    "}\n",
    "\n",
    "regressors_model = [\n",
    "    'physio', 'out_ons', 'out_perr', 'ppi_out_ons', 'ppi_out_perr', \n",
    "    'dec_ons', 'dec_miss', 'dec_wcor', 'res_lbp', 'res_rbp', 'res_miss', \n",
    "    'out_off'\n",
    "]\n",
    "regressors_save = ['physio', 'out_perr', 'ppi_out_perr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate PPI model\n",
    "\n",
    "This part generates and evaluates separate PPI GLMs for each subject, task condition and pair of ROIs. \n",
    "\n",
    "- create all model regressors\n",
    "- create design matrix\n",
    "- run linear model\n",
    "- store results\n",
    "\n",
    "> Note that for different subject / task entities design matrix may have or not have two additional regressors (miss for decision onset and miss for decision offset). Some subjects didn't miss any response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory tpsycho-1500_tppi-1500_nRegs-12.\n",
      "1.5 1.5 saving sub-m02_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m03_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m04_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m05_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m06_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m07_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m08_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m09_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m10_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m11_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m12_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m13_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m14_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m15_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m16_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m17_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m18_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m19_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m20_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m21_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m22_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m23_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m24_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m25_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m26_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m27_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m28_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m29_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m30_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m31_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m32_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m33_task-rew_betamats.npy\n",
      "1.5 1.5 saving sub-m02_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m03_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m04_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m05_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m06_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m07_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m08_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m09_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m10_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m11_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m12_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m13_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m14_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m15_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m16_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m17_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m18_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m19_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m20_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m21_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m22_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m23_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m24_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m25_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m26_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m27_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m28_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m29_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m30_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m31_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m32_task-pun_betamats.npy\n",
      "1.5 1.5 saving sub-m33_task-pun_betamats.npy\n"
     ]
    }
   ],
   "source": [
    "for t_event_psycho, t_event_ppi in product((0, 0.5, 1, 1.5), repeat=2):\n",
    "    \n",
    "    if t_event_ppi != 1.5 or t_event_psycho != 1.5:\n",
    "        continue\n",
    "\n",
    "    options.update(t_event_psycho=t_event_psycho, t_event_ppi=t_event_ppi)\n",
    "\n",
    "    # Create paths to store output data and plots\n",
    "    dirname_components = [\n",
    "        f'tpsycho-{int(options[\"t_event_psycho\"] * 1000)}',\n",
    "        f'tppi-{int(options[\"t_event_ppi\"] * 1000)}',\n",
    "        f'nRegs-{len(regressors_model)}'\n",
    "    ]\n",
    "    if options['binarize_perr']:\n",
    "        dirname_components.append('binarizedPerr')\n",
    "    if options['binarize_wcor']:\n",
    "        dirname_components.append('binarizedWcor')\n",
    "    dirname = '_'.join(dirname_components)\n",
    "\n",
    "    path_save = join(path_results, dirname)\n",
    "    print(f'Creating directory {dirname}.')\n",
    "    Path(path_save).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    if options['save_dm_plots']:\n",
    "        path_save_dm = join(path_save, 'design_matrices')\n",
    "        Path(path_save_dm).mkdir(exist_ok=True, parents=True)\n",
    "    if options['save_reg_corr_plots']:\n",
    "        path_save_reg_corr = join(path_save, 'regressors_correlation')\n",
    "        Path(path_save_reg_corr).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Store settings in JSON file\n",
    "    with open(join(path_save, 'options_betamats.json'), 'w') as json_file:    \n",
    "        json.dump(dict(\n",
    "            regressors_model=regressors_model,\n",
    "            regressors_save=regressors_save,\n",
    "            **options\n",
    "        ), json_file, sort_keys=True, indent=4)    \n",
    "\n",
    "\n",
    "    n_regressors_save = len(regressors_save)  \n",
    "\n",
    "    for con, con_name in enumerate(meta['dim2']):\n",
    "        for sub, sub_name in enumerate(meta['dim1']):\n",
    "\n",
    "            beta_mats = np.zeros((n_regressors_save, n_rois, n_rois))\n",
    "\n",
    "            # Extract task events\n",
    "            resp_type = beh[sub, con, :, meta['dim4'].index('response')]\n",
    "            onset_out = beh[sub, con, :, meta['dim4'].index('onset_out')]\n",
    "            onset_dec = beh[sub, con, :, meta['dim4'].index('onset_dec')] \n",
    "            onset_res = beh[sub, con, :, meta['dim4'].index('onset_dec')] + \\\n",
    "                        beh[sub, con, :, meta['dim4'].index('rt')]\n",
    "            offset_dec = onset_dec + t_dec\n",
    "            offset_out = onset_out + t_out\n",
    "\n",
    "            # Extract behavioral variables\n",
    "            if options['binarize_wcor']:\n",
    "                modulation_wcor = np.sign(modulations_wcor[sub, con, resp_type != 0])\n",
    "            else:\n",
    "                modulation_wcor = modulations_wcor[sub, con, resp_type != 0]\n",
    "            if options['binarize_perr']:\n",
    "                modulation_perr = np.sign(modulations_perr[sub, con])\n",
    "            else:\n",
    "                modulation_perr = modulations_perr[sub, con]\n",
    "            modulation_wcor_demeaned = modulation_wcor - np.mean(modulation_wcor)\n",
    "            modulation_perr_demeaned = modulation_perr - np.mean(modulation_perr)\n",
    "\n",
    "            for idx_seed in range(n_rois):\n",
    "\n",
    "                # Physiological regressor (seed time-series)\n",
    "                reg_physio = Regressor.from_values(\n",
    "                    'physio', \n",
    "                    frame_times, \n",
    "                    timeseries_denoised_aggregated[sub, con, :, idx_seed])            \n",
    "\n",
    "                # Psychological regressors \n",
    "                reg_out_perr = Regressor(\n",
    "                    name='out_perr', \n",
    "                    frame_times=frame_times,\n",
    "                    duration=np.ones(n_trials) * t_event_psycho, \n",
    "                    onset=onset_out,\n",
    "                    modulation=modulation_perr_demeaned)\n",
    "                reg_out_ons = Regressor(\n",
    "                    name='out_ons', \n",
    "                    frame_times=frame_times,\n",
    "                    duration=np.ones(n_trials) * t_event_psycho, \n",
    "                    onset=onset_out)\n",
    "\n",
    "                # PPI regressors\n",
    "                ts_neural_up = timeseries_neural_aggregated[sub, con, :, idx_seed]\n",
    "\n",
    "                ts_out_perr_up = upsampled_events(\n",
    "                    t_r=t_r,\n",
    "                    n_volumes=n_volumes,\n",
    "                    onset=onset_out,\n",
    "                    duration=t_event_ppi, \n",
    "                    modulation=modulation_perr_demeaned)\n",
    "                ts_out_ons_up = upsampled_events(\n",
    "                    t_r=t_r,\n",
    "                    n_volumes=n_volumes,\n",
    "                    onset=onset_out,\n",
    "                    duration=t_event_ppi)\n",
    "\n",
    "                # Point by point multiplication\n",
    "                ts_ppi_out_perr_up = ts_neural_up * ts_out_perr_up\n",
    "                ts_ppi_out_ons_up = ts_neural_up * ts_out_ons_up\n",
    "\n",
    "                # Reconvolution\n",
    "                reg_ppi_out_perr = Regressor.from_values(\n",
    "                    'ppi_out_perr',\n",
    "                    frame_times,\n",
    "                    values=convolve(ts_ppi_out_perr_up, t_r=t_r*sampling_rate)[downsamples])\n",
    "                reg_ppi_out_ons = Regressor.from_values(\n",
    "                    'ppi_out_ons',\n",
    "                    frame_times,\n",
    "                    values=convolve(ts_ppi_out_ons_up, t_r=t_r*sampling_rate)[downsamples])\n",
    "\n",
    "                # No-interest regressors\n",
    "                reg_dec_ons = Regressor(\n",
    "                    'dec_ons', \n",
    "                    frame_times, \n",
    "                    onset_dec[resp_type != 0],\n",
    "                    duration=np.ones(len(onset_dec[resp_type != 0])) * t_event_psycho)\n",
    "                reg_dec_miss = Regressor(\n",
    "                    'dec_miss', \n",
    "                    frame_times, \n",
    "                    onset_dec[resp_type == 0],\n",
    "                    duration=np.ones(len(onset_dec[resp_type == 0])) * t_event_psycho)\n",
    "                reg_dec_wcor = Regressor(\n",
    "                    'dec_wcor', \n",
    "                    frame_times, \n",
    "                    onset_dec[resp_type != 0],\n",
    "                    duration=np.ones(len(onset_dec[resp_type != 0])) * t_event_psycho,\n",
    "                    modulation=modulation_wcor_demeaned)\n",
    "                reg_res_lbp = Regressor(\n",
    "                    'res_lbp', \n",
    "                    frame_times, \n",
    "                    onset_res[resp_type == -1],\n",
    "                    duration=np.ones(len(onset_res[resp_type == -1])) * t_event_psycho)\n",
    "                reg_res_rbp = Regressor(\n",
    "                    'res_rbp', \n",
    "                    frame_times, \n",
    "                    onset_res[resp_type == 1],\n",
    "                    duration=np.ones(len(onset_res[resp_type == 1])) * t_event_psycho)\n",
    "                reg_res_miss = Regressor(\n",
    "                    'res_miss', \n",
    "                    frame_times, \n",
    "                    offset_dec[resp_type == 0],            \n",
    "                    duration=np.ones(len(offset_dec[resp_type == 0])) * t_event_psycho)\n",
    "                reg_out_off = Regressor(\n",
    "                    'out_off', \n",
    "                    frame_times, \n",
    "                    offset_out,\n",
    "                    duration=np.ones(len(offset_out)) * t_event_psycho)\n",
    "\n",
    "                # Aggregate regressors\n",
    "                regressors_all = [\n",
    "                    reg_physio,                              # physiological\n",
    "                    reg_out_ons, reg_out_perr,               # main psychological\n",
    "                    reg_ppi_out_ons, reg_ppi_out_perr,       # PPI\n",
    "                    reg_dec_ons, reg_dec_miss, reg_dec_wcor, # no-interest (dec)\n",
    "                    reg_res_lbp, reg_res_rbp, reg_res_miss,  # no-interest (res)\n",
    "                    reg_out_off                              # no-interest (out)\n",
    "                ]\n",
    "                regressors = list(filter(lambda r: r.name in regressors_model, \n",
    "                                         regressors_all))\n",
    "\n",
    "                # Create design matrix\n",
    "                X, _ = my_make_first_level_design_matrix(regressors)\n",
    "                X = X[[c for c in X.columns if 'drift' not in c]]\n",
    "                X = X.drop('constant', axis=1)\n",
    "                Xstd = (X - X.mean()) / X.std()\n",
    "                Xstd['reg_intercept'] = np.ones(n_volumes)\n",
    "\n",
    "                # Save design matrix plot and regressor correlation plot\n",
    "                if options['save_dm_plots']:\n",
    "                    fname = '_'.join((\n",
    "                        f'sub-{sub_name}', \n",
    "                        f'task-{con_name}', \n",
    "                        f'seed-{roi_labels[idx_seed]}',\n",
    "                        'dmplot.png'))\n",
    "                    dm_plot_fname = join(path_save_dm, fname)\n",
    "                    plot_design_matrix(\n",
    "                        Xstd, \n",
    "                        colors=[beta_colors[c] for c in Xstd.columns],\n",
    "                        output_file=dm_plot_fname)      \n",
    "                if options['save_reg_corr_plots']:\n",
    "                    fname = '_'.join((\n",
    "                        f'sub-{sub_name}', \n",
    "                        f'task-{con_name}', \n",
    "                        f'seed-{roi_labels[idx_seed]}',\n",
    "                        'regcorrplot.png'))\n",
    "                    reg_corr_plot_fname = join(path_save_reg_corr, fname)\n",
    "                    plot_regressors_correlation(\n",
    "                        Xstd,\n",
    "                        colors=[beta_colors[c] for c in Xstd.columns], \n",
    "                        output_file=reg_corr_plot_fname)\n",
    "\n",
    "                for idx_target in range(n_rois):        \n",
    "\n",
    "                    # Modeled response (target time-series)\n",
    "                    y = pd.DataFrame(\n",
    "                        timeseries_denoised_aggregated[sub, con, :, idx_target],\n",
    "                        columns=['target'], \n",
    "                        index=frame_times)\n",
    "\n",
    "                    # Fit GLM\n",
    "                    model = sm.OLS(y, Xstd, hasconst=True)\n",
    "                    results = model.fit()\n",
    "                    beta_mats[:, idx_target, idx_seed] = results.params.loc[regressors_save]               \n",
    "\n",
    "            # Save beta estimates\n",
    "            fname = f'sub-{sub_name}_task-{con_name}_betamats.npy'\n",
    "            print(f'{t_event_ppi} {t_event_psycho} saving {fname}')\n",
    "            np.save(join(path_save, fname), beta_mats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
