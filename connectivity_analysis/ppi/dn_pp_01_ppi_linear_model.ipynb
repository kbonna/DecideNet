{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPI General Linear Model\n",
    "\n",
    "Here, PPI network construction is performed by evaluating multiple linear models and extracting regressors beta weights. PPI linear model takes form: \n",
    "\n",
    "$$y=\\beta_0\n",
    "+\\beta_1\\cdot x_{physio}\n",
    "+\\beta_2\\cdot x_{out\\_ons}\n",
    "+\\beta_3\\cdot x_{out\\_perr}\n",
    "+\\beta_4\\cdot x_{PPI:out\\_ons}\n",
    "+\\beta_5\\cdot x_{PPI:out\\_perr}\n",
    "+\\beta_6\\cdot x_{dec\\_ons}\n",
    "+\\beta_7\\cdot x_{dec\\_miss}\n",
    "+\\beta_8\\cdot x_{dec\\_wcor}\n",
    "+\\beta_9\\cdot x_{res\\_lbp}\n",
    "+\\beta_{10}\\cdot x_{res\\_rbp}\n",
    "+\\beta_{11}\\cdot x_{res\\_miss}\n",
    "+\\beta_{12}\\cdot x_{out\\_off}$$\n",
    "\n",
    "Detailed regressors description:\n",
    "\n",
    "| Regressor | Type | Description | Event Duration\n",
    "|:--:|----|----|----|\n",
    "| `y` | physiological | BOLD signal from target region | – |\n",
    "| | | | |\n",
    "| `physio` | physiological | BOLD signal from seed region | – |\n",
    "| `out_ons` | psychological | outcome phase onset | `t_event_psycho` |\n",
    "| `out_perr` | psychological | outcome phase onset parametrically modulated with prediction error | `t_event_psycho` |\n",
    "| `ppi_out_ons` | interaction | `out_ons` point-by-point multiplied with <br />deconvolved seed timeseries, reconvolved with HRF | `t_event_ppi` \n",
    "| **`ppi_out_perr`** | interaction | `out_perr` point-by-point multiplied with <br />deconvolved seed timeseries, reconvolved with HRF | `t_event_ppi` |\n",
    "| `dec_ons` | psychological | decision phase onset | `t_event_psycho` |\n",
    "| `dec_miss` | psychological | decision phase onset for trials with missing response | `t_event_psycho` |\n",
    "| `dec_wcor` | psychological | decision phase onset parametrically modulated with expected probability of being correct | `t_event_psycho` |\n",
    "| `res_lbp` | psychological | left button press onset | `t_event_psycho` |\n",
    "| `res_rbp` | psychological | right button press onset | `t_event_psycho` |\n",
    "| `res_miss` | psychological | onset of isi phase for trials with missing response | `t_event_psycho` |\n",
    "| `out_off` | psychological | outcome phase offset | `t_event_psycho` |\n",
    "| `intercept` | other | intercept for linear model | – |\n",
    "\n",
    "Each type of regressor was calculated differently: \n",
    "- **physiological regressors**: BOLD signals extracted using `NiftiSpheresMasker`. Before extraction confounds (24 head motion parameters, CSF and WM signals, squares, temporal derivatives and squares of temporal derivatives) and low-frequency drift were removed and signal was high pass-filtered (128s), \n",
    "- **psychological regressors**: task events convolved with canonical HRF using `compute_regressor` function from `nistats.hemodynamic_models` wrapped in custom `Regressor` class for consistent treating standard and parametrically modulated regressor, \n",
    "- **interaction (PPI) regressors**: first, ROIs timeseries were extracted with detrending and high-pass filtering. Then they were deconvolved using spm fuction for parameter estimation Bayes `spm_PEB.m`. Deconvolved and upsampled (by default 16 times) ROI timeseries were point-by-point multiplied with upsampled and demeaned task events timeseries to create interaction regressor in neural space. Finally, these interaction regressors were reconvolved with HRF and downsampled to create PPI regressors in BOLD space.\n",
    "\n",
    "---\n",
    "**Last update**: 31.08.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmb/Desktop/Neuroscience/Projects/BONNA_decide_net/code/dn_utils/glm_utils.py:13: FutureWarning: \n",
      "\n",
      " | Starting with Nilearn 0.7.0, all Nistats functionality has been incorporated into Nilearn's stats & reporting modules.\n",
      " | Nistats package will no longer be updated or maintained.\n",
      "\n",
      "  from nistats import design_matrix\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.regression.linear_model as sm\n",
    "from bids import BIDSLayout\n",
    "from IPython.display import clear_output\n",
    "from scipy import io\n",
    "from scipy.stats import zscore\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = os.path.join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.behavioral_models import load_behavioral_data\n",
    "from dn_utils.glm_utils import (convolve, Regressor, upsampled_events,\n",
    "                                my_make_first_level_design_matrix)\n",
    "from dn_utils.plotting import plot_design_matrix, plot_regressors_correlation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beh.shape (32, 2, 110, 23)\n",
      "modulations_wcor.shape (32, 2, 110)\n",
      "modulations_perr.shape (32, 2, 110)\n",
      "timeseries_neural_aggregated.shape (32, 2, 11680, 14)\n",
      "timeseries_denoised_aggregated.shape (32, 2, 730, 14)\n",
      "downsamples.shape (730,)\n"
     ]
    }
   ],
   "source": [
    "# Directory for PPI analysis\n",
    "path_nistats = os.path.join(path_root, 'data/main_fmri_study/derivatives/nistats')\n",
    "path_out = os.path.join(path_root, 'data/main_fmri_study/derivatives/ppi')\n",
    "path_betamats = os.path.join(path_out, 'betamats')\n",
    "path_timeries = os.path.join(path_out, 'timeseries')\n",
    "path_parcellations = os.path.join(path_out, 'parcellations')\n",
    "\n",
    "# Load behavioral data\n",
    "path_beh = os.path.join(path_root, 'data/main_fmri_study/sourcedata/behavioral')\n",
    "beh, meta = load_behavioral_data(path=path_beh, verbose=False)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape\n",
    "\n",
    "# Load trial modulations\n",
    "path_modulations = os.path.join(path_nistats, 'modulations')\n",
    "modulations_wcor = np.load(os.path.join(path_modulations, \n",
    "                                        'modulations_wcor.npy'))\n",
    "modulations_perr = np.load(os.path.join(path_modulations, \n",
    "                                        'modulations_perr.npy'))\n",
    "\n",
    "# Load neural & BOLD timeseries\n",
    "data = io.loadmat(os.path.join(\n",
    "    path_timeries, \n",
    "    'timeseries_pipeline-24HMPCSFWM_atlas-customROI_neural.mat'))\n",
    "timeseries_neural_aggregated = data['timeseries_neural_aggregated']\n",
    "timeseries_denoised_aggregated = np.load(os.path.join(\n",
    "    path_timeries, \n",
    "    'timeseries_pipeline-24HMPCSFWM_atlas-customROI_bold.npy'))\n",
    "downsamples = data['k'].flatten()\n",
    "\n",
    "# Load region labels\n",
    "with open(os.path.join(path_parcellations, \n",
    "                       'custom_roi/custom_roi_labels.txt'), 'r') as f:\n",
    "    roi_labels = f.read().splitlines() \n",
    "roi_labels = [label.replace('_', '')[:-1] + label[-1].lower() \n",
    "              for label in roi_labels]\n",
    "    \n",
    "# Create directory for output\n",
    "atlas_name = 'customROI'\n",
    "path_results = os.path.join(path_betamats, atlas_name)\n",
    "Path(path_results).mkdir(exist_ok=True)\n",
    "\n",
    "# Acquisition parameters\n",
    "_, _, n_volumes, n_rois = timeseries_denoised_aggregated.shape\n",
    "t_r = 2\n",
    "frame_times = np.arange(n_volumes) * t_r\n",
    "\n",
    "# Duration of phases\n",
    "t_dec, t_out = 1.5, 1.5\n",
    "\n",
    "# Upsampling rate for deconvolved signal\n",
    "sampling_rate = 1/16\n",
    "\n",
    "# Input data shape\n",
    "print('beh.shape', beh.shape)\n",
    "print('modulations_wcor.shape', modulations_wcor.shape)\n",
    "print('modulations_perr.shape', modulations_perr.shape)\n",
    "print('timeseries_neural_aggregated.shape', timeseries_neural_aggregated.shape)\n",
    "print('timeseries_denoised_aggregated.shape', timeseries_denoised_aggregated.shape)\n",
    "print('downsamples.shape', downsamples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI GLM events duration\n",
    "- `t_event_psycho`: duration of all psychological events (e.g. button press)\n",
    "- `t_event_ppi`: duration of psychological events for upsampled regressors\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_event_psycho = 1\n",
    "t_event_ppi = 1\n",
    "\n",
    "# Create paths to store output data\n",
    "path_save = os.path.join(\n",
    "    path_results, \n",
    "    f'tpsycho-{int(t_event_psycho * 1000)}_tppi-{int(t_event_ppi * 1000)}')\n",
    "path_save_dm = os.path.join(\n",
    "    path_save, 'design_matrices'\n",
    ")\n",
    "path_save_reg_corr = os.path.join(\n",
    "    path_save, 'regressors_correlation'\n",
    ")\n",
    "\n",
    "Path(path_save_dm).mkdir(exist_ok=True, parents=True)\n",
    "Path(path_save_reg_corr).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create design matrix\n",
    "\n",
    "> Note that for different subject / task entities design matrix may have or not have two additional regressors (miss for decision onset and miss for decision offset). Some subjects didn't miss any response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant regressors to save (regressors that all models have)\n",
    "beta_names = ['physio', \n",
    "              'out_ons', 'out_perr', \n",
    "              'ppi_out_ons', 'ppi_out_perr', \n",
    "              'dec_ons', 'dec_wcor', \n",
    "              'res_lbp', 'res_rbp',\n",
    "              'out_off', \n",
    "              'reg_intercept']\n",
    "\n",
    "# Keys are all regressors (even miss regressors which some of participants may \n",
    "# not have)\n",
    "beta_colors = {\n",
    "    'physio': 'tab:red', \n",
    "    'out_ons': 'tab:blue',\n",
    "    'out_perr': 'tab:purple',\n",
    "    'ppi_out_ons': 'tab:green',\n",
    "    'ppi_out_perr': 'tab:orange',\n",
    "    'dec_ons': 'tab:blue',\n",
    "    'dec_miss': 'tab:blue',\n",
    "    'dec_wcor':'tab:purple',\n",
    "    'res_lbp': 'tab:blue',\n",
    "    'res_rbp': 'tab:blue',\n",
    "    'res_miss': 'tab:blue',\n",
    "    'out_off': 'tab:blue',\n",
    "    'reg_intercept': 'tab:gray'\n",
    "}\n",
    "\n",
    "n_regressors = len(beta_names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving sub-m02_task-rew_betamats.npy\n",
      "saving sub-m03_task-rew_betamats.npy\n",
      "saving sub-m04_task-rew_betamats.npy\n",
      "saving sub-m05_task-rew_betamats.npy\n",
      "saving sub-m06_task-rew_betamats.npy\n",
      "saving sub-m07_task-rew_betamats.npy\n",
      "saving sub-m08_task-rew_betamats.npy\n",
      "saving sub-m09_task-rew_betamats.npy\n",
      "saving sub-m10_task-rew_betamats.npy\n",
      "saving sub-m11_task-rew_betamats.npy\n",
      "saving sub-m12_task-rew_betamats.npy\n",
      "saving sub-m13_task-rew_betamats.npy\n",
      "saving sub-m14_task-rew_betamats.npy\n",
      "saving sub-m15_task-rew_betamats.npy\n",
      "saving sub-m16_task-rew_betamats.npy\n",
      "saving sub-m17_task-rew_betamats.npy\n",
      "saving sub-m18_task-rew_betamats.npy\n",
      "saving sub-m19_task-rew_betamats.npy\n",
      "saving sub-m20_task-rew_betamats.npy\n",
      "saving sub-m21_task-rew_betamats.npy\n",
      "saving sub-m22_task-rew_betamats.npy\n",
      "saving sub-m23_task-rew_betamats.npy\n",
      "saving sub-m24_task-rew_betamats.npy\n",
      "saving sub-m25_task-rew_betamats.npy\n",
      "saving sub-m26_task-rew_betamats.npy\n",
      "saving sub-m27_task-rew_betamats.npy\n",
      "saving sub-m28_task-rew_betamats.npy\n",
      "saving sub-m29_task-rew_betamats.npy\n",
      "saving sub-m30_task-rew_betamats.npy\n",
      "saving sub-m31_task-rew_betamats.npy\n",
      "saving sub-m32_task-rew_betamats.npy\n",
      "saving sub-m33_task-rew_betamats.npy\n",
      "saving sub-m02_task-pun_betamats.npy\n",
      "saving sub-m03_task-pun_betamats.npy\n",
      "saving sub-m04_task-pun_betamats.npy\n",
      "saving sub-m05_task-pun_betamats.npy\n",
      "saving sub-m06_task-pun_betamats.npy\n",
      "saving sub-m07_task-pun_betamats.npy\n",
      "saving sub-m08_task-pun_betamats.npy\n",
      "saving sub-m09_task-pun_betamats.npy\n",
      "saving sub-m10_task-pun_betamats.npy\n",
      "saving sub-m11_task-pun_betamats.npy\n",
      "saving sub-m12_task-pun_betamats.npy\n",
      "saving sub-m13_task-pun_betamats.npy\n",
      "saving sub-m14_task-pun_betamats.npy\n",
      "saving sub-m15_task-pun_betamats.npy\n",
      "saving sub-m16_task-pun_betamats.npy\n",
      "saving sub-m17_task-pun_betamats.npy\n",
      "saving sub-m18_task-pun_betamats.npy\n",
      "saving sub-m19_task-pun_betamats.npy\n",
      "saving sub-m20_task-pun_betamats.npy\n",
      "saving sub-m21_task-pun_betamats.npy\n",
      "saving sub-m22_task-pun_betamats.npy\n",
      "saving sub-m23_task-pun_betamats.npy\n",
      "saving sub-m24_task-pun_betamats.npy\n",
      "saving sub-m25_task-pun_betamats.npy\n",
      "saving sub-m26_task-pun_betamats.npy\n",
      "saving sub-m27_task-pun_betamats.npy\n",
      "saving sub-m28_task-pun_betamats.npy\n",
      "saving sub-m29_task-pun_betamats.npy\n",
      "saving sub-m30_task-pun_betamats.npy\n",
      "saving sub-m31_task-pun_betamats.npy\n",
      "saving sub-m32_task-pun_betamats.npy\n",
      "saving sub-m33_task-pun_betamats.npy\n"
     ]
    }
   ],
   "source": [
    "for con, con_name in enumerate(meta['dim2']):\n",
    "    for sub, sub_name in enumerate(meta['dim1']):\n",
    "\n",
    "        beta_mats = np.zeros((n_regressors, n_rois, n_rois))\n",
    "        #pval_mats = np.zeros((n_regressors, n_rois, n_rois))\n",
    "        #tval_mats = np.zeros((n_regressors, n_rois, n_rois))\n",
    "        \n",
    "        # Extract task events\n",
    "        resp_type = beh[sub, con, :, meta['dim4'].index('response')]\n",
    "        onset_out = beh[sub, con, :, meta['dim4'].index('onset_out')]\n",
    "        onset_dec = beh[sub, con, :, meta['dim4'].index('onset_dec')] \n",
    "        onset_res = beh[sub, con, :, meta['dim4'].index('onset_dec')] + \\\n",
    "                    beh[sub, con, :, meta['dim4'].index('rt')]\n",
    "        offset_dec = onset_dec + t_dec\n",
    "        offset_out = onset_out + t_out\n",
    "\n",
    "        modulation_wcor = modulations_wcor[sub, con, resp_type != 0]\n",
    "        modulation_perr = modulations_perr[sub, con]\n",
    "        modulation_wcor_demeaned = modulation_wcor - np.mean(modulation_wcor)\n",
    "        modulation_perr_demeaned = modulation_perr - np.mean(modulation_perr)\n",
    "\n",
    "        for idx_seed in range(n_rois):\n",
    "\n",
    "            # Physiological regressor (seed time-series)\n",
    "            reg_physio = Regressor.from_values(\n",
    "                'physio', \n",
    "                frame_times, \n",
    "                timeseries_denoised_aggregated[sub, con, :, idx_seed])            \n",
    "\n",
    "            # Psychological regressors \n",
    "            reg_out_perr = Regressor(\n",
    "                name='out_perr', \n",
    "                frame_times=frame_times,\n",
    "                duration=np.ones(n_trials) * t_event_psycho, \n",
    "                onset=onset_out,\n",
    "                modulation=modulation_perr_demeaned)\n",
    "            reg_out_ons = Regressor(\n",
    "                name='out_ons', \n",
    "                frame_times=frame_times,\n",
    "                duration=np.ones(n_trials) * t_event_psycho, \n",
    "                onset=onset_out)\n",
    "\n",
    "            # PPI regressors\n",
    "            ts_neural_up = timeseries_neural_aggregated[sub, con, :, idx_seed]\n",
    "\n",
    "            ts_out_perr_up = upsampled_events(\n",
    "                t_r=t_r,\n",
    "                n_volumes=n_volumes,\n",
    "                onset=onset_out,\n",
    "                duration=t_event_ppi, \n",
    "                modulation=modulation_perr_demeaned)\n",
    "            ts_out_ons_up = upsampled_events(\n",
    "                t_r=t_r,\n",
    "                n_volumes=n_volumes,\n",
    "                onset=onset_out,\n",
    "                duration=t_event_ppi)\n",
    "\n",
    "            # Point by point multiplication\n",
    "            ts_ppi_out_perr_up = ts_neural_up * ts_out_perr_up\n",
    "            ts_ppi_out_ons_up = ts_neural_up * ts_out_ons_up\n",
    "\n",
    "            # Reconvolution\n",
    "            reg_ppi_out_perr = Regressor.from_values(\n",
    "                'ppi_out_perr',\n",
    "                frame_times,\n",
    "                values=convolve(ts_ppi_out_perr_up, t_r=t_r*sampling_rate)[downsamples]\n",
    "            )\n",
    "            reg_ppi_out_ons = Regressor.from_values(\n",
    "                'ppi_out_ons',\n",
    "                frame_times,\n",
    "                values=convolve(ts_ppi_out_ons_up, t_r=t_r*sampling_rate)[downsamples]\n",
    "            )\n",
    "\n",
    "            # No-interest regressors\n",
    "            reg_dec_ons = Regressor(\n",
    "                'dec_ons', \n",
    "                frame_times, \n",
    "                onset_dec[resp_type != 0],\n",
    "                duration=np.ones(len(onset_dec[resp_type != 0])) * t_event_psycho)\n",
    "            reg_dec_miss = Regressor(\n",
    "                'dec_miss', \n",
    "                frame_times, \n",
    "                onset_dec[resp_type == 0],\n",
    "                duration=np.ones(len(onset_dec[resp_type == 0])) * t_event_psycho)\n",
    "            reg_dec_wcor = Regressor(\n",
    "                'dec_wcor', \n",
    "                frame_times, \n",
    "                onset_dec[resp_type != 0],\n",
    "                duration=np.ones(len(onset_dec[resp_type != 0])) * t_event_psycho,\n",
    "                modulation=modulation_wcor_demeaned)\n",
    "            reg_res_lbp = Regressor(\n",
    "                'res_lbp', \n",
    "                frame_times, \n",
    "                onset_res[resp_type == -1],\n",
    "                duration=np.ones(len(onset_res[resp_type == -1])) * t_event_psycho)\n",
    "            reg_res_rbp = Regressor(\n",
    "                'res_rbp', \n",
    "                frame_times, \n",
    "                onset_res[resp_type == 1],\n",
    "                duration=np.ones(len(onset_res[resp_type == 1])) * t_event_psycho)\n",
    "            reg_res_miss = Regressor(\n",
    "                'res_miss', \n",
    "                frame_times, \n",
    "                offset_dec[resp_type == 0],            \n",
    "                duration=np.ones(len(offset_dec[resp_type == 0])) * t_event_psycho)\n",
    "            reg_out_off = Regressor(\n",
    "                'out_off', \n",
    "                frame_times, \n",
    "                offset_out,\n",
    "                duration=np.ones(len(offset_out)) * t_event_psycho)\n",
    "\n",
    "            # Create design matrix\n",
    "            regressors = [\n",
    "                reg_physio,                              # physiological\n",
    "                reg_out_ons, reg_out_perr,               # main psychological\n",
    "                reg_ppi_out_ons, reg_ppi_out_perr,       # PPI\n",
    "                reg_dec_ons, reg_dec_miss, reg_dec_wcor, # no-interest (dec)\n",
    "                reg_res_lbp, reg_res_rbp, reg_res_miss,  # no-interest (res)\n",
    "                reg_out_off                              # no-interest (out)\n",
    "            ] \n",
    "\n",
    "            # Create design matrix\n",
    "            X, _ = my_make_first_level_design_matrix(regressors)\n",
    "            X = X[[c for c in X.columns if 'drift' not in c]]\n",
    "            X = X.drop('constant', axis=1)\n",
    "            Xstd = (X - X.mean()) / X.std()\n",
    "            Xstd['reg_intercept'] = np.ones(n_volumes)\n",
    "            \n",
    "            # Save design matrix plot and regressor correlation plot\n",
    "            dm_plot_fname = os.path.join(\n",
    "                path_save_dm, \n",
    "                f'sub-{sub_name}_task-{con_name}_seed-{roi_labels[idx_seed]}' \\\n",
    "                + '_dmplot.png'\n",
    "            )\n",
    "            reg_corr_plot_fname = os.path.join(\n",
    "                path_save_reg_corr, \n",
    "                f'sub-{sub_name}_task-{con_name}_seed-{roi_labels[idx_seed]}' \\\n",
    "                + '_regcorrplot.png'\n",
    "            )\n",
    "            plot_design_matrix(\n",
    "                Xstd, \n",
    "                colors=[beta_colors[c] for c in Xstd.columns],\n",
    "                output_file=dm_plot_fname\n",
    "            )\n",
    "            plot_regressors_correlation(\n",
    "                Xstd, \n",
    "                colors=[beta_colors[c] for c in Xstd.columns], \n",
    "                output_file=reg_corr_plot_fname\n",
    "            )\n",
    "            \n",
    "            for idx_target in range(n_rois):        \n",
    "                \n",
    "                # Modeled response (target time-series)\n",
    "                y = pd.DataFrame(\n",
    "                    timeseries_denoised_aggregated[sub, con, :, idx_target],\n",
    "                    columns=['target'], \n",
    "                    index=frame_times)\n",
    "\n",
    "                # Fit GLM\n",
    "                model = sm.OLS(y, Xstd, hasconst=True)\n",
    "                results = model.fit()\n",
    "                \n",
    "                beta_mats[:, idx_target, idx_seed] = results.params.loc[beta_names]\n",
    "                #pval_mats[:, idx_target, idx_seed] = results.pvalues.loc[beta_names]\n",
    "                #tval_mats[:, idx_target, idx_seed] = results.tvalues.loc[beta_names]\n",
    "                \n",
    "                \n",
    "        # Save beta estimates\n",
    "        print(f'saving sub-{sub_name}_task-{con_name}_betamats.npy')\n",
    "        fname = os.path.join(\n",
    "            path_save, \n",
    "            f'sub-{sub_name}_task-{con_name}_betamats.npy')\n",
    "        np.save(fname, beta_mats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
