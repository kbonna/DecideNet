{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI signal extraction\n",
    "\n",
    "This script performs extraction and cleaning of BOLD signal from predefined brain regions. These signals are used to perform PPI GLM modeling. Two versions of signals are prepared â€“ **raw** (without confound removal) and **clean** (with confounds removed). Raw version is used for deconvolution implemented in `spm_peb_ppi.m` whereas clean version is used for custom deconvolution using Ridge regression. For both versions signal is:\n",
    "- standardized using z-score\n",
    "- detrended\n",
    "- high pass filtered with 128s cut-off\n",
    "\n",
    "Then signal is extracted from all predefined ROIs. For clean version, 24 head motion parameters (hmp) are included as confounds, raw version omit regressing out any confounds. Output data is stored in two aggregate arrays with signals for all subjects, conditions and rois (both have shape $N_{subjects} \\times N_{conditions} \\times N_{volumes} \\times N_{rois}$):\n",
    "- `time_series_clean_all`: signals with hmp variability removed\n",
    "- `time_series_raw_all`: signal with no confoud removal\n",
    "\n",
    "---\n",
    "**Last update**: 28.04.2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from bids import BIDSLayout\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "from scipy import io\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = os.path.join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.behavioral_models import load_behavioral_data                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for PPI analysis\n",
    "path_out = os.path.join(path_root, \n",
    "                        'data/main_fmri_study/derivatives/ppi')\n",
    "os.makedirs(path_out, exist_ok=True)\n",
    "\n",
    "path_parcellations = os.path.join(path_out, 'parcellations')\n",
    "path_timeries = os.path.join(path_out, 'timeseries')\n",
    "\n",
    "# Atlases\n",
    "path_300_roi = os.path.join(path_parcellations, '300_ROI_Set/ROIs_300inVol_MNI_allInfo.txt')\n",
    "\n",
    "# Load behavioral data\n",
    "path_beh = os.path.join(path_root, 'data/main_fmri_study/sourcedata/behavioral')\n",
    "beh, meta = load_behavioral_data(path=path_beh)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape\n",
    "n_volumes = 730"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query neuroimaging dataset\n",
    "\n",
    "Using BIDSLayout object query BIDS dataset to pull out necessary files.\n",
    "- `fmri_files`: list of two lists containing sorted (by subject number) paths to imaging files, first list corresponds to reward condition of PRL task and second list corresponds to punishment condition of PRL task\n",
    "- `conf_files`: list of two lists containing sorted (by subject number) paths to confound files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bids = os.path.join(path_root, 'data/main_fmri_study')\n",
    "\n",
    "layout = BIDSLayout(\n",
    "    root=path_bids,\n",
    "    derivatives=True,\n",
    "    validate=True,\n",
    "    index_metadata=False\n",
    ")\n",
    "\n",
    "fmri_filter = {\n",
    "    \"extension\": [\".nii\", \".nii.gz\"],\n",
    "    \"space\": \"MNI152NLin2009cAsym\",\n",
    "    \"suffix\": \"bold\",\n",
    "    \"desc\": \"preproc\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "conf_filter = {\n",
    "    \"extension\": \"tsv\",\n",
    "    \"desc\": \"confounds\",\n",
    "    \"return_type\": \"filename\"\n",
    "}\n",
    "\n",
    "fmri_files, conf_files = [], []\n",
    "\n",
    "for task_dict in [{\"task\": \"prlrew\"}, {\"task\": \"prlpun\"}]:\n",
    "    fmri_filter.update(task_dict)\n",
    "    conf_filter.update(task_dict)\n",
    "    fmri_files.append(layout.get(**fmri_filter))\n",
    "    conf_files.append(layout.get(**conf_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load brain parcellation\n",
    "\n",
    "Here brain parcellation is loaded. Parcellaton should be stored and formatted as csv file with (at least these) columns:\n",
    "\n",
    "| Column Name | Description |\n",
    "|:--:|----|\n",
    "| `x` | x MNI coordinate for ROI center | \n",
    "| `y` | y MNI coordinate for ROI center | \n",
    "| `z` | z MNI coordinate for ROI center | \n",
    "| `radius(mm)` | sphere radius in mm |\n",
    "\n",
    "Since `NiftiSpheresMasker` class accepts only single radius value, different maskers are created for all unique radii values (if needed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_atlas = path_300_roi\n",
    "\n",
    "df_atlas = pd.read_csv(path_300_roi, sep=' ')\n",
    "seeds = [tuple(coords[1]) for coords in df_atlas[['x', 'y', 'z']].iterrows()]\n",
    "n_rois = len(seeds)\n",
    "\n",
    "# Dict for storing maskers for different radii values\n",
    "rois = {}\n",
    "\n",
    "for radius in df_atlas['radius(mm)'].unique():\n",
    "    # Select ROIs with given radius\n",
    "    roi_indices = np.flatnonzero(df_atlas['radius(mm)'] == radius)\n",
    "    \n",
    "    # Create masker for single radius value\n",
    "    masker = NiftiSpheresMasker(\n",
    "        [seeds[idx] for idx in roi_indices], \n",
    "        radius=radius,                \n",
    "        mask_img=None,            \n",
    "        allow_overlap=True, \n",
    "        standardize='zscore', \n",
    "        detrend=True, \n",
    "        high_pass=1/128,\n",
    "        t_r=2\n",
    "    )\n",
    "    \n",
    "    rois[radius] = {'masker': masker, 'indices': roi_indices}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and clean signal\n",
    "\n",
    "Resulting timecourses are stored in 4-dimensional array with dimensions corresponding to subjects, tasks, volumes and roi's. Matrix shape is `n_subjects` $\\times$ `n_conditions` $\\times$ `n_volumes` $\\times$ `n_rois`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_clean_all = np.zeros((n_subjects, n_conditions, n_volumes, n_rois))\n",
    "time_series_raw_all = np.zeros((n_subjects, n_conditions, n_volumes, n_rois))\n",
    "confounds_hmp_all = np.zeros((n_subjects, n_conditions, n_volumes, 24))\n",
    "\n",
    "for task_idx in range(n_conditions):\n",
    "    for sub_idx in range(n_subjects):\n",
    "        \n",
    "        fmri_fname = fmri_files[task_idx][sub_idx]\n",
    "        conf_fname = conf_files[task_idx][sub_idx]\n",
    "\n",
    "        # Read confounds, filtering & save confounds\n",
    "        conf_df = pd.read_csv(conf_fname, sep='\\t')\n",
    "        conf_df = conf_df.filter(regex='rot|trans')\n",
    "        conf_df = conf_df.fillna(0)\n",
    "\n",
    "        tmp_fname = 'temp'\n",
    "        conf_df.to_csv(tmp_fname)\n",
    "\n",
    "        time_series_clean = np.zeros((n_volumes, n_rois))\n",
    "        time_series_raw = np.zeros((n_volumes, n_rois))\n",
    "        for radius in rois:\n",
    "            # Get indices to insert computed timeseries into right positions\n",
    "            roi_indices = rois[radius]['indices']\n",
    "\n",
    "            # Extract timeseries\n",
    "            time_series_clean[:, roi_indices] = rois[radius]['masker'].fit_transform(\n",
    "                fmri_fname,\n",
    "                confounds=tmp_fname\n",
    "            )\n",
    "            time_series_raw[:, roi_indices] = rois[radius]['masker'].fit_transform(\n",
    "                fmri_fname,\n",
    "                confounds=None\n",
    "            )\n",
    "            \n",
    "        # Store results in corresponding arrays\n",
    "        time_series_clean_all[sub_idx][task_idx] = time_series_clean\n",
    "        time_series_raw_all[sub_idx][task_idx] = time_series_raw\n",
    "        confounds_hmp_all[sub_idx][task_idx] = conf_df\n",
    "        \n",
    "        os.remove(tmp_fname)\n",
    "    \n",
    "# Save in numpy format\n",
    "np.save(os.path.join(path_timeries, 'time_series_clean_all'), time_series_clean_all)\n",
    "\n",
    "# Save for further SPM use\n",
    "io.savemat(os.path.join(path_timeries, 'time_series_raw_all.mat'), \n",
    "           {'time_series_raw_all': time_series_raw_all})\n",
    "io.savemat(os.path.join(path_timeries, 'confounds_hmp_all.mat'),\n",
    "           {'confounds_hmp_all': confounds_hmp_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot extracted signal from single subject\n",
    "\n",
    "Show carpet plot of cleaned BOLD signal from all predefined ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10), facecolor='w')\n",
    "\n",
    "carpet = ax.imshow(\n",
    "    time_series_clean_all[0][0].T, \n",
    "    aspect='auto',\n",
    "    cmap='gray'\n",
    ")\n",
    "\n",
    "ax.set_ylabel('ROI')\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_xticklabels([f'{t:.0f}' for t in 2 * ax.get_xticks()])\n",
    "ax.set_title('ROI Timecourse Carpetplot')\n",
    "\n",
    "fig.colorbar(carpet, pad=0.01, shrink=1, aspect=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 64-bit ('decidenet': conda)",
   "language": "python",
   "name": "decidenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
