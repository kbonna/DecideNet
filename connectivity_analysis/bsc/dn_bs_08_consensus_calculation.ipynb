{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excellent-passion",
   "metadata": {},
   "source": [
    "# Consensus partitions calculation\n",
    "\n",
    "Here representative module partitions are calculated for entire task and condition classes. First, agreement matrix $D$ between all partitions of interest is calculated. An element of agreement matrix $D_{ij}$ represents the number of times that nodes $i$ and $j$ are placed within the same module. Then, agreement matrix $D$ is normalized to reflect the probability that two nodes are a part of the same community (given random partition). Normalized agreemnent matrix is then thresholded at $\\tau$ level, equal to `consensus_tau` (here 0.5), to remove weak associations. Resulting matrix is then reclustered using Louvain algorithm `consensus_reps` times. Analysis results in five representative partitions: \n",
    "- `all`: entire task partition\n",
    "- `rew`: reward-seeking condition parition\n",
    "- `pun`: punishment-avoiding condition partition\n",
    "- `inc`: increasing (positive) prediciton error partition\n",
    "- `dec`: decreasing (negative) prediction error partition\n",
    "\n",
    "Partitions are stored under `consensus_tau_<consensus_tau>.json` file within:\n",
    "```\n",
    "└── <atlas_name>\n",
    "    └── <threshold>\n",
    "        ├── gamma_<louvain_gamma>\n",
    "        │   ├── consensus_tau_0_5.json\n",
    "        │   ├── consensus_tau_0_75.json\n",
    "        │   └── ...\n",
    "```\n",
    "Output JSON file contains keys representing different partition classes and values corresponding to partition vector. It also contains other metadata like `consensus_tau` and `consensus_reps` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "first-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bct.algorithms.clustering import agreement, consensus_und\n",
    "from dn_utils.path import path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "british-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = \"combined_roi_4and5\"\n",
    "gamma_range = np.arange(0.5, 2, 0.5)\n",
    "\n",
    "consensus_tau = 0.5\n",
    "consensus_reps = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ruled-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph measures\n",
    "path_corrmats = join(path[\"bsc\"], \"corrmats\")\n",
    "path_corrmats_unthr = join(path_corrmats, atlas, \"unthr\")\n",
    "\n",
    "m = {}\n",
    "for gamma in gamma_range:\n",
    "    gamma_str = str(float(gamma)).replace(\".\", \"_\")\n",
    "    path_corrmats_unthr_gamma = join(path_corrmats_unthr, f\"gamma_{gamma_str}\")\n",
    "    m[gamma] = np.load(join(path_corrmats_unthr_gamma, \"m_aggregated.npy\"))\n",
    "\n",
    "# Load subject exclusion\n",
    "df_exclusion = pd.read_csv(join(path[\"nistats\"], \"exclusion/exclusion.csv\"), \n",
    "                           index_col=0)\n",
    "ok_index = df_exclusion[\"ok_all\"]\n",
    "\n",
    "# Meta information about corrmats dimensions\n",
    "with open(join(path_corrmats, atlas, \"corrmats_aggregated.json\"), \"r\") as f:\n",
    "    corrmats_meta = json.loads(f.read()) \n",
    "    \n",
    "n_subjects_ok = sum(ok_index)\n",
    "n_conditions = len(corrmats_meta[\"dim2\"])\n",
    "n_perr_sign = len(corrmats_meta[\"dim3\"])\n",
    "n_roi = len(corrmats_meta[\"dim4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "average-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γ = 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce869b1dc4284fbe8a1e3fccd3cea920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γ = 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86825d6d6064637b26b3251c0856ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γ = 1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa0114218e94ed19729a029face0cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for gamma in gamma_range:\n",
    "\n",
    "    print(f\"γ = {gamma}\")\n",
    "    \n",
    "    consensus = {}\n",
    "    \n",
    "    mt = m[gamma][ok_index]\n",
    "    m_all = np.reshape(mt, (n_subjects_ok * n_conditions * n_perr_sign, n_roi))\n",
    "    m_rew = np.reshape(mt[:, 0], (n_subjects_ok * n_perr_sign, n_roi))\n",
    "    m_pun = np.reshape(mt[:, 1], (n_subjects_ok * n_perr_sign, n_roi))\n",
    "    m_inc = np.reshape(mt[:, :, 0], (n_subjects_ok * n_perr_sign, n_roi))\n",
    "    m_dec = np.reshape(mt[:, :, 1], (n_subjects_ok * n_perr_sign, n_roi))\n",
    "\n",
    "    for k, v in tqdm([(\"all\", m_all), (\"rew\", m_rew), (\"pun\", m_pun), \n",
    "                      (\"inc\", m_inc), (\"dec\", m_dec)]):\n",
    "\n",
    "        D = agreement(v.T) / len(v)\n",
    "        consensus_array = consensus_und(\n",
    "            D, tau=consensus_tau, reps=consensus_reps)\n",
    "        \n",
    "        # Coerce to int so it is JSON serializable\n",
    "        consensus[k] = [int(i) for i in consensus_array]\n",
    "    \n",
    "    # Save as JSON file\n",
    "    consensus[\"consensus_reps\"] = consensus_reps\n",
    "    gamma_str = str(float(gamma)).replace(\".\", \"_\")\n",
    "    tau_str = str(float(consensus_tau)).replace(\".\", \"_\")    \n",
    "    path_corrmats_unthr_gamma = join(path_corrmats_unthr, f\"gamma_{gamma_str}\")\n",
    "    path_json = join(path_corrmats_unthr_gamma, f\"consensus_tau_{tau_str}.json\")\n",
    "        \n",
    "    with open(path_json, \"w\") as f:\n",
    "        f.write(json.dumps(consensus, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
