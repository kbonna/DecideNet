{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network randomization\n",
    "\n",
    "Here, permutation testing is used to asess significant connectivity between LSNs. Association between two LSNs is considered significant when mean connection strenght between them is higher that 95% values from null distribution. \n",
    "\n",
    "Null distribution of between LSN connectivity is calculated using `n_nulls` random networks. Each random network have same total strenght and degree distribution (but not strenght distribution) as original network. Algorithm to rewire network edges `randmio_und` comes from BCT. Each edge is rewired approximately `n_rewirings` times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "from os.path import join\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bct.algorithms.reference import randmio_und, null_model_und_sign\n",
    "from bct.utils import BCTParamError\n",
    "from dn_utils.plotting import plot_matrix\n",
    "from dn_utils.networks import networks_mean\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = os.environ.get(\"DECIDENET_PATH\")\n",
    "\n",
    "path_derivatives = join(path_root, \"data/main_fmri_study/derivatives\")\n",
    "path_sourcedata = join(path_root, \"data/main_fmri_study/sourcedata\") \n",
    "\n",
    "path_beh = join(path_sourcedata, \"behavioral\")\n",
    "path_bsc = join(path_derivatives, \"bsc\")\n",
    "path_nistats = join(path_derivatives, \"nistats\")\n",
    "path_parcellations = join(path_derivatives, \"parcellations\")\n",
    "\n",
    "path_corrmats = join(path_bsc, \"corrmats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input networks\n",
    "atlas = \"combined_roi\"\n",
    "alpha_fdr = 1e-10\n",
    "\n",
    "# Randomization options\n",
    "n_nulls = 5\n",
    "n_rewirings = 1\n",
    "\n",
    "# Create output paths\n",
    "alpha_fdr_str = str(alpha_fdr).replace(\"-\", \"\")\n",
    "path_out = join(path_corrmats, atlas, f\"fdrthr_{alpha_fdr_str}\")\n",
    "path_nulls = join(path_out, \"nulls\")\n",
    "pathlib.Path(path_nulls).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correlation matrices and metadata\n",
    "corrmats_aggregated = np.load(join(path_corrmats, atlas, \n",
    "                                   \"corrmats_aggregated.npy\"))\n",
    "with open(join(path_corrmats, atlas, \"corrmats_aggregated.json\"), \"r\") as f:\n",
    "    meta = json.loads(f.read())\n",
    "\n",
    "# Load subject exclusion\n",
    "df_exclusion = pd.read_csv(join(path_nistats, \"exclusion/exclusion.csv\"), \n",
    "                           index_col=0)\n",
    "ok_index = df_exclusion[\"ok_all\"]    \n",
    "    \n",
    "# Load ROI information\n",
    "df_roi = pd.read_csv(join(path_corrmats, atlas, \"roi_table_filtered.csv\"))\n",
    "netnames = df_roi[\"netName\"].unique()\n",
    "\n",
    "n_subjects = len(meta[\"dim1\"])\n",
    "n_conditions = len(meta[\"dim2\"])\n",
    "n_perr_sign = len(meta[\"dim3\"])\n",
    "n_rois = len(df_roi)\n",
    "n_nets = len(netnames)\n",
    "\n",
    "# Load pvalue mask\n",
    "pvalues_mask = np.load(join(path_out, f\"pvalues_mask.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding\n",
    "corrmats_aggregated_thr = corrmats_aggregated * pvalues_mask\n",
    "corrmats_aggregated_thr = corrmats_aggregated_thr * (corrmats_aggregated_thr > 0)\n",
    "\n",
    "for con_idx, con in enumerate(meta[\"dim2\"]):\n",
    "    for perr_sign_idx, perr_sign in enumerate(meta[\"dim3\"]):\n",
    "        for sub_idx, sub in enumerate(meta[\"dim1\"]): \n",
    "            print(f\"Randomizing {sub} | {con} | {perr_sign}\")\n",
    "\n",
    "            # Extract correlation matrix & clean diagonal\n",
    "            corrmat = corrmats_aggregated_thr[sub_idx, con_idx, perr_sign_idx]\n",
    "            corrmat[np.diag_indices_from(corrmat)] = 0\n",
    "\n",
    "            meanmat_nulls = np.zeros((n_nulls, n_nets, n_nets))\n",
    "            \n",
    "            for rep in tqdm(range(n_nulls)):\n",
    "\n",
    "                # Randomize network\n",
    "                try:\n",
    "#                     corrmat_null, _  = null_model_und_sign(corrmat, n_rewirings)\n",
    "                    corrmat_null, _  = randmio_und(corrmat, n_rewirings)\n",
    "                except BCTParamError:\n",
    "                    # In case of non-symmetrical matrix from failed acquisition\n",
    "                    corrmat_null = np.zeros((n_rois, n_rois))\n",
    "\n",
    "                # Calculate lsn mean connectivity & store\n",
    "                _, meanmat_nulls[rep] = networks_mean(corrmat_null, \n",
    "                                                      df_roi[\"netName\"])\n",
    "\n",
    "            fname = f\"sub-{sub}_task-prl{con}_perrsign-{perr_sign[-3:]}_nullmeanmats.npy\"\n",
    "            np.save(join(path_nulls, fname), meanmat_nulls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
