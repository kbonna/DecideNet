{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betaseries extraction\n",
    "\n",
    "This script combines calculated whole brain trial beta-maps with brain parcellation and extracts trial beta-series for predefined set of brain regions. This analysis step has to be conducted separately for each parcellation. `NiftiSpheresMasker` is used for signal extraction with parameters:\n",
    "- `allow_overlap=False`: ensures that parcellation has no everlapping spheres\n",
    "- `standardize=True`: z-scores signal along trials dimension\n",
    "- `detrend=False`: disable detrending since we are no longer in a time domain\n",
    "- `high_pass=None`: disable high-pass filtering\n",
    "- `low_pass=None`: disable low-pass filtering\n",
    "\n",
    "Use of brain mask can be enabled / disabled by setting `use_mask` flag. Note that due to signal dropout in orbitofrontal regions, that will likely lead to an error raised by masker (some ROIs will fall out of the mask). Therefore by default `use_mask=False`. Spheres outside of the brain mask â€“ i.e. these without signal, will be removed in the next analysis step during network construction. \n",
    "\n",
    "Additional within-condition normalization step can be performed by setting `within_condition_normalization` flag to `True`. This step is described in ([Conrad et al., 2020](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7462424/); see section \"Within-format Normalization\"). This procedure is adapted from the MVPA literature in which normalization of beta values is employed prior to classifier training.\n",
    "\n",
    "After extraction, data from all subject and both task conditions are aggregated into single `.npy` file for convenience. Output file is stored as:\n",
    "\n",
    "> `betaseries/<atlas_name>/betaseries_aggregated_<suffix>.npy`\n",
    "\n",
    "Output array has shape `n_subjects` x `n_conditions` x `n_trials` x `n_rois`. Metadata corresponding to first thee dimensions can be found in `behavioral_data_clean_all.json` file. Suffix can be `norm` if within-condition normalization is performed or missing otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dn_utils.behavioral_models import load_behavioral_data\n",
    "from dn_utils.misc import normalize_4d_nifti\n",
    "from dn_utils.path import path\n",
    "from nibabel.funcs import concat_images, four_to_three\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select brain parcellation & masker options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = \"combined_roi\"\n",
    "roi_table_fname = \"combined_roi_table.csv\"\n",
    "\n",
    "# Arguments for NiftiSpheresMasker\n",
    "masker_kwargs = {\n",
    "    \"allow_overlap\": False, \n",
    "    \"standardize\": True, \n",
    "    \"detrend\": False, \n",
    "    \"high_pass\": None,\n",
    "    \"low_pass\": None\n",
    "}\n",
    "\n",
    "# Whether to use individual brain mask during signal extraction\n",
    "use_mask = False\n",
    "\n",
    "# Within-conditon normaliation\n",
    "within_condition_normalization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paths\n",
    "path_betamaps = join(path[\"bsc\"], \"betamaps\")\n",
    "path_betaseries = join(path[\"bsc\"], \"betaseries\")\n",
    "Path(path_betaseries).mkdir(exist_ok=True)\n",
    "\n",
    "# Load ROI data\n",
    "df_roi = pd.read_csv(join(path[\"parcellations\"], atlas, roi_table_fname))\n",
    "\n",
    "# Load behavioral data\n",
    "beh, meta = load_behavioral_data(path[\"behavioral\"], verbose=False)\n",
    "n_subjects = beh.shape[0]\n",
    "n_conditions = beh.shape[1]\n",
    "n_trials = beh.shape[2]\n",
    "\n",
    "# Load masks\n",
    "with open(join(path[\"data_paths\"], \"mask_filenames.json\"), \"r\") as f:\n",
    "    mask_files = json.loads(f.read())\n",
    "\n",
    "# Load betamaps\n",
    "imgs = {\"prlrew\": [], \"prlpun\": []}\n",
    "for con_idx, con in enumerate(meta[\"dim2\"]):\n",
    "    for sub_idx, sub in enumerate(meta[\"dim1\"]):\n",
    "        img_fname = f\"sub-{sub}_task-prl{con}_betamaps.nii.gz\" \n",
    "        imgs[f\"prl{con}\"].append(nib.load(join(path_betamaps, img_fname)))\n",
    "        \n",
    "df_roi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within-condition normalization\n",
    "\n",
    "Optional step of within-condition normalization of betamaps. In order to ensure that differences in activity or variance between conditons do not affect connectivity estimates, within-condition normalization procedure is implemented. Betamaps are first separated by condition and concatenated, then each voxel-wise beta series is normalized (mean subtraction and standard deviation division).\n",
    "\n",
    "> This step will be performed only if `within_condition_normalization` flag is set to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if within_condition_normalization:\n",
    "    print(\"Normalizing images...\")\n",
    "    \n",
    "    imgs_norm = {\n",
    "        \"prlpun\": [None for _ in range(n_subjects)], \n",
    "        \"prlrew\": [None for _ in range(n_subjects)]\n",
    "    }\n",
    "\n",
    "    for sub_idx, sub in enumerate(tqdm(meta[\"dim1\"])):\n",
    "        for con_idx, con in enumerate(meta[\"dim2\"]):\n",
    "\n",
    "            won_bool_idx = meta[\"dim4\"].index(\"won_bool\")\n",
    "            won_bool = beh[sub_idx, con_idx, :, won_bool_idx].astype(bool)\n",
    "            won_indices = list(np.where(won_bool)[0])\n",
    "            los_indices = list(np.where(~won_bool)[0])        \n",
    "\n",
    "            # Grab 4d image\n",
    "            con_key = f\"prl{con}\"\n",
    "            img = imgs[con_key][sub_idx]\n",
    "\n",
    "            # Split according to condition\n",
    "            img_list = four_to_three(img)\n",
    "            won_img_list = [img_3d for i, img_3d \n",
    "                            in enumerate(img_list) if i in won_indices]\n",
    "            los_img_list = [img_3d for i, img_3d in \n",
    "                            enumerate(img_list) if i in los_indices]\n",
    "\n",
    "            # Within-condition normalizitation\n",
    "            img_list_norm = [None for _ in range(n_trials)]\n",
    "            won_img_list_norm = normalize_4d_nifti(concat_images(won_img_list))\n",
    "            los_img_list_norm = normalize_4d_nifti(concat_images(los_img_list))\n",
    "\n",
    "            # Put normalized images back in place & concatenate\n",
    "            for i, img_3d in zip(won_indices, won_img_list_norm):\n",
    "                img_list_norm[i] = img_3d\n",
    "            for i, img_3d in zip(los_indices, los_img_list_norm):\n",
    "                img_list_norm[i] = img_3d\n",
    "            img_norm = concat_images(img_list_norm)\n",
    "\n",
    "            imgs_norm[con_key][sub_idx] = img_norm\n",
    "else: \n",
    "    print(\"Skipping normalization...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create maskers\n",
    "\n",
    "Here separate maskers are created for ROIs with different sphere diameter. It is required for parcellations with uneven ROIs, since nilearn doesn't support variable ROI size. In standard case of uniform ROI size, this step is unnecessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rois = len(df_roi)\n",
    "seeds = [tuple(coords[1]) for coords in df_roi[[\"x\", \"y\", \"z\"]].iterrows()]\n",
    "\n",
    "maskers = {}\n",
    "\n",
    "for radius in df_roi[\"radius(mm)\"].unique():\n",
    "    # Select ROIs with given radius\n",
    "    roi_indices = np.flatnonzero(df_roi[\"radius(mm)\"] == radius)\n",
    "    \n",
    "    # Create masker for single radius value\n",
    "    masker = NiftiSpheresMasker(\n",
    "        [seeds[idx] for idx in roi_indices], \n",
    "        radius=radius,                \n",
    "        mask_img=None,\n",
    "        **masker_kwargs\n",
    "    )\n",
    "    \n",
    "    maskers[radius] = {\"masker\": masker, \"indices\": roi_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betaseries_aggregated = np.zeros((n_subjects, n_conditions, n_trials, n_rois))\n",
    "\n",
    "for sub_idx, sub in enumerate(tqdm(meta[\"dim1\"])):\n",
    "    for con_idx, con in enumerate(meta[\"dim2\"]):\n",
    "\n",
    "        mask_img = nib.load(mask_files[f\"prl{con}\"][sub_idx])\n",
    "        \n",
    "        if within_condition_normalization:\n",
    "            beta_img = imgs_norm[f\"prl{con}\"][sub_idx]\n",
    "        else:\n",
    "            beta_img = imgs[f\"prl{con}\"][sub_idx]\n",
    "\n",
    "        betaseries = np.zeros((n_trials, n_rois))\n",
    "\n",
    "        for radius in maskers:\n",
    "            # Get indices to insert computed timeseries into right positions\n",
    "            roi_indices = maskers[radius][\"indices\"]\n",
    "\n",
    "            # Get right spheres masker and add right whole-brain mask \n",
    "            masker = maskers[radius][\"masker\"]\n",
    "            \n",
    "            # Apply mask\n",
    "            if use_mask:\n",
    "                masker.mask_img = mask_img\n",
    "\n",
    "            # Extract timeseries          \n",
    "            betaseries[:, roi_indices] = masker.fit_transform(beta_img)\n",
    "                \n",
    "        betaseries_aggregated[sub_idx, con_idx] = betaseries\n",
    "        \n",
    "# Store betaseries\n",
    "suffix = \"_norm\" if within_condition_normalization else \"\"\n",
    "Path(join(path_betaseries, atlas)).mkdir(exist_ok=True, parents=True)\n",
    "np.save(join(path_betaseries, atlas, f\"betaseries_aggregated{suffix}.npy\"), \n",
    "        betaseries_aggregated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
