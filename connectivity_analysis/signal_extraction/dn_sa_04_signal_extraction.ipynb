{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI signal extraction\n",
    "\n",
    "...\n",
    "\n",
    "---\n",
    "**Last update**: xx.xx.2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from bids import BIDSLayout\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "from scipy import io\n",
    "\n",
    "path_root = os.environ.get('DECIDENET_PATH')\n",
    "path_code = os.path.join(path_root, 'code')\n",
    "if path_code not in sys.path:\n",
    "    sys.path.append(path_code)\n",
    "from dn_utils.behavioral_models import load_behavioral_data                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for PPI analysis\n",
    "path_out = os.path.join(path_root, 'data/main_fmri_study/derivatives/ppi')\n",
    "path_parcellations = os.path.join(path_out, 'parcellations')\n",
    "path_timeries = os.path.join(path_out, 'timeseries')\n",
    "path_bids = os.path.join(path_root, 'data/main_fmri_study')\n",
    "path_fmridenoise = os.path.join(path_bids, 'derivatives/fmridenoise')\n",
    "\n",
    "# Atlases\n",
    "path_custom_roi = ''\n",
    "path_300_roi = os.path.join(path_parcellations, \n",
    "                            '300_ROI_Set/ROIs_300inVol_MNI_allInfo.txt')\n",
    "\n",
    "# Load behavioral data\n",
    "path_beh = os.path.join(path_root, 'data/main_fmri_study/sourcedata/behavioral')\n",
    "beh, meta = load_behavioral_data(path=path_beh, verbose=False)\n",
    "n_subjects, n_conditions, n_trials, _ = beh.shape\n",
    "n_volumes = 730\n",
    "n_confounds = 32\n",
    "\n",
    "# Name of the pipeline used for fMRI data denoising\n",
    "denoising_pipeline_name = '24HMPCSFWM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query neuroimaging dataset\n",
    "\n",
    "Grab necessary fMRI files:\n",
    "- `fmri_files_raw`: dictionary with keys corresponding to task condition lables and values being list of paths to preprocessed imaging files\n",
    "- `fmri_files_denoised`: dictionary with keys corresponding to task condition lables and values being list of paths to preprocessed and denoised imaging files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(\n",
    "    root=path_bids,\n",
    "    derivatives=True,\n",
    "    validate=True,\n",
    "    index_metadata=False\n",
    ")\n",
    "\n",
    "fmri_filter = {\n",
    "    'extension': ['.nii', '.nii.gz'],\n",
    "    'space': 'MNI152NLin2009cAsym',\n",
    "    'suffix': 'bold',\n",
    "    'desc': 'preproc',\n",
    "    'return_type': 'filename'\n",
    "}\n",
    "\n",
    "fmri_files_raw = {}\n",
    "fmri_files_denoised = {}\n",
    "\n",
    "for task_dict in [{'task': 'prlrew'}, {'task': 'prlpun'}]:\n",
    "    fmri_filter.update(task_dict)\n",
    "    fmri_files_raw[task_dict['task']] = layout.get(**fmri_filter)\n",
    "    fmri_files_denoised[task_dict['task']] = sorted([\n",
    "        os.path.join(path_fmridenoise, fname) \n",
    "        for fname in os.listdir(path_fmridenoise) \n",
    "        if task_dict['task'] in fname\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose brain parcellation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_atlas = path_300_roi\n",
    "atlas_name = '300ROI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load brain parcellation\n",
    "\n",
    "Here brain parcellation is loaded. Parcellaton should be stored and formatted as csv file with (at least these) columns:\n",
    "\n",
    "| Column Name | Description |\n",
    "|:--:|----|\n",
    "| `x` | x MNI coordinate for ROI center | \n",
    "| `y` | y MNI coordinate for ROI center | \n",
    "| `z` | z MNI coordinate for ROI center | \n",
    "| `radius(mm)` | sphere radius in mm |\n",
    "\n",
    "Since `NiftiSpheresMasker` class accepts only single radius value, different maskers are created for all unique radii values (if needed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atlas = pd.read_csv(path_atlas, sep=' ')\n",
    "seeds = [tuple(coords[1]) for coords in df_atlas[['x', 'y', 'z']].iterrows()]\n",
    "n_rois = len(seeds)\n",
    "\n",
    "# Dict for storing maskers for different radii values\n",
    "rois = {}\n",
    "\n",
    "for radius in df_atlas['radius(mm)'].unique():\n",
    "    # Select ROIs with given radius\n",
    "    roi_indices = np.flatnonzero(df_atlas['radius(mm)'] == radius)\n",
    "    \n",
    "    # Create masker for single radius value\n",
    "    masker = NiftiSpheresMasker(\n",
    "        [seeds[idx] for idx in roi_indices], \n",
    "        radius=radius,                \n",
    "        mask_img=None,            \n",
    "        allow_overlap=True, \n",
    "        standardize='zscore', \n",
    "        detrend=True, \n",
    "        high_pass=1/128,\n",
    "        t_r=2\n",
    "    )\n",
    "    \n",
    "    rois[radius] = {'masker': masker, 'indices': roi_indices}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract signal\n",
    "\n",
    "Resulting timecourses are stored in 4-dimensional array with dimensions corresponding to subjects, tasks, volumes and roi's. \n",
    "\n",
    "Matrix shape is `n_subjects` $\\times$ `n_conditions` $\\times$ `n_volumes` $\\times$ `n_rois`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_denoised_aggregated = np.zeros(\n",
    "    (n_subjects, n_conditions, n_volumes, n_rois))\n",
    "timeseries_raw_aggregated = np.zeros(\n",
    "    (n_subjects, n_conditions, n_volumes, n_rois))\n",
    "\n",
    "for con_idx, con_name in enumerate(meta['dim2']):    \n",
    "    for sub_idx, sub_name in enumerate(meta['dim1']):\n",
    "        \n",
    "        fmri_file_raw = fmri_files_raw[f'prl{con_name}'][sub_idx]\n",
    "        fmri_file_denoised = fmri_files_denoised[f'prl{con_name}'][sub_idx]\n",
    "\n",
    "        timeseries_denoised = np.zeros((n_volumes, n_rois))\n",
    "        timeseries_raw = np.zeros((n_volumes, n_rois))\n",
    "        \n",
    "        for radius in rois:\n",
    "            # Get indices to insert computed timeseries into right positions\n",
    "            roi_indices = rois[radius]['indices']\n",
    "\n",
    "            # Extract timeseries\n",
    "            timeseries_denoised[:, roi_indices] = rois[radius]['masker'].fit_transform(\n",
    "                fmri_file_denoised, confounds=None\n",
    "            )\n",
    "            timeseries_raw[:, roi_indices] = rois[radius]['masker'].fit_transform(\n",
    "                fmri_file_raw, confounds=None\n",
    "            )\n",
    "            \n",
    "        # Store results in corresponding arrays\n",
    "        timeseries_denoised_aggregated[sub_idx][con_idx] = timeseries_denoised\n",
    "        timeseries_raw_aggregated[sub_idx][con_idx] = timeseries_raw\n",
    "\n",
    "    \n",
    "fname_denoised = f'timeseries_pipeline-{denoising_pipeline_name}_atlas-{atlas_name}_bold'\n",
    "fname_raw = f'timeseries_pipeline-null_atlas-{atlas_name}_bold'\n",
    "    \n",
    "# Save in numpy format\n",
    "np.save(os.path.join(\n",
    "    path_timeries, fname_denoised), \n",
    "    timeseries_denoised_aggregated)\n",
    "np.save(os.path.join(\n",
    "    path_timeries, fname_raw), \n",
    "    timeseries_raw_aggregated)\n",
    "\n",
    "# Save for further SPM use\n",
    "io.savemat(os.path.join(path_timeries, fname_denoised + '.mat'), \n",
    "           {'timeseries_denoised_aggregated': timeseries_denoised_aggregated})\n",
    "io.savemat(os.path.join(path_timeries, fname_raw + '.mat'), \n",
    "           {'timeseries_raw_aggregated': timeseries_raw_aggregated})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot extracted signal from single subject\n",
    "\n",
    "Show carpet plot of cleaned BOLD signal from all predefined ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10), facecolor='w')\n",
    "\n",
    "carpet = ax.imshow(\n",
    "    timeseries_denoised_aggregated[0][0].T, \n",
    "    aspect='auto',\n",
    "    cmap='gray'\n",
    ")\n",
    "\n",
    "ax.set_ylabel('ROI')\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_xticklabels([f'{t:.0f}' for t in 2 * ax.get_xticks()])\n",
    "ax.set_title('ROI Timecourse Carpetplot')\n",
    "\n",
    "fig.colorbar(carpet, pad=0.01, shrink=1, aspect=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
